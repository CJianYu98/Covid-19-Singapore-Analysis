{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "cwd = os.path.abspath('') \n",
    "files = os.listdir(cwd)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.chdir(r\"C:\\Users\\limst\\Documents\\github\\Covid-19-Singapore-Analysis\\Data\\Facebook Data\\Cleaned Data\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "files = os.listdir(cwd)\n",
    "files"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#create a dataframe to store the merged data for each platform\n",
    "df = pd.DataFrame()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for file in files:\n",
    "     if file.endswith('csv'):\n",
    "            df = df.append(pd.read_csv(file), ignore_index=True) \n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import datetime\n",
    "import emoji\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(pattern = \"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_hashtag_mentions_urls(text):\n",
    "    return re.sub(r\"(?:\\@|\\#|https?\\://)\\S+\", \"\", text)\n",
    "\n",
    "def stopwords_ls(additional_stopwords):\n",
    "    stop_list = stopwords.words('english')\n",
    "    for word in additional_stopwords:\n",
    "        stop_list.append(word)\n",
    "    \n",
    "    return stop_list\n",
    "\n",
    "def text_preprocessing(df, column_name, stopword_list):\n",
    "    output = []\n",
    "    for text in df[column_name]:\n",
    "        text = remove_hashtag_mentions_urls(text)\n",
    "        text = remove_emoji(text)\n",
    "        text_lower = [w.lower() for w in text_tokenize]\n",
    "        text_words_only = [w for w in text_lower if re.search('^[a-z]+$',w)]\n",
    "        text_stopremoved = [w for w in text_words_only if w not in stopword_list]\n",
    "\n",
    "        output.append(text_stopremoved)\n",
    "\n",
    "    return output\n",
    "\n",
    "def demojize_text(df, column_name):\n",
    "    emoji_decoded_tweets = []\n",
    "\n",
    "    for text in df[column_name]:\n",
    "        text = emoji.demojize(text)\n",
    "        \n",
    "        emoji_decoded_tweets.append(text)\n",
    "    \n",
    "    return emoji_decoded_tweets\n",
    "\n",
    "def instagram_text_processing(df, stopword_list):\n",
    "\n",
    "    text_processed = text_preprocessing(df, 'comment', stopword_list)\n",
    "\n",
    "    text_demojize = demojize_text(df, 'comment')\n",
    "\n",
    "    df['processed_text'] = text_processed\n",
    "    df['demojize_text'] = text_demojize\n",
    "\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\n",
    "import emoji\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "tweet = df['Comment']\n",
    "cleaned_text = []\n",
    "for i in range(len(tweet)):\n",
    "    text = tweet[i]\n",
    "    # removing mentions, hashtags, URLs from tweet\n",
    "    text = re.sub(r\"(?:\\@|\\#|https?\\://)\\S+\", \"\", text)\n",
    "    text = remove_emoji(text)\n",
    "    #separates the sentence by words\n",
    "    text_tokenize = word_tokenize(text)\n",
    "\n",
    "    text_lower = [w.lower() for w in text_tokenize]\n",
    "    #removes anything that are not alphabets\n",
    "    text_words_only = [w for w in text_lower if re.search('^[a-z]+$',w)]\n",
    "    text_joined = \" \".join(text_words_only)\n",
    "    cleaned_text.append(text_joined)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_facebook = \" \".join(row for row in cleaned_text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#create a mask of the photo that you want to use\n",
    "instagram_mask = np.array(Image.open(\"facebook_logo.png\"))\n",
    "#photos that have values all zero are not recommended\n",
    "instagram_mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# Import image to np.array\n",
    "# Generate wordcloud\n",
    "#method 1 (uses colormap)\n",
    "image_colors = ImageColorGenerator(instagram_mask)\n",
    "cloud = WordCloud(width = 3000, height = 2000, background_color='white', colormap='rainbow', collocations=False, stopwords = STOPWORDS, mask=instagram_mask,contour_color='black',contour_width=2).generate(all_facebook)\n",
    "# Plot\n",
    "plt.figure(figsize=[7,7])\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.axis(\"off\");\n",
    "#saving the wordcloud\n",
    "cloud.to_file('facebook.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#method 2 (uses get_single_color_func)\n",
    "import wordcloud as wc\n",
    "\n",
    "cloud = wc.WordCloud(stopwords=STOPWORDS,color_func=wc.get_single_color_func('darkorange'),\n",
    "                    background_color='white',max_words=2000,random_state=42,\n",
    "                    width=2000, height=1000,mask=instagram_mask,contour_color='black',contour_width=2).generate(all_tweets)\n",
    "plt.figure(figsize=[7,7])\n",
    "\n",
    "plt.imshow(cloud,interpolation='bilinear')\n",
    "plt.axis(\"off\");\n",
    "#cloud.to_file(\"reddit.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#method 3 (uses colour from the picture)\n",
    "import wordcloud as wc\n",
    "image_colors = ImageColorGenerator(instagram_mask)\n",
    "cloud = wc.WordCloud(stopwords=STOPWORDS,color_func=image_colors,\n",
    "                    background_color='white',max_words=2000,random_state=42,\n",
    "                    width=2000, height=1000,mask=instagram_mask,contour_color='black',contour_width=2).generate(all_tweets)\n",
    "plt.figure(figsize=[7,7])\n",
    "\n",
    "plt.imshow(cloud,interpolation='bilinear')\n",
    "plt.axis(\"off\");\n",
    "cloud.to_file(\"reddit1.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#also uses colour from the picture \n",
    "wordcloud = WordCloud(stopwords=STOPWORDS, background_color=\"white\", width=2000, height=1000,mask=instagram_mask,mode = \"RGBA\").generate(all_facebook)\n",
    "image_colors = ImageColorGenerator(instagram_mask)\n",
    "# Display the generated image:\n",
    "#plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.figure(figsize=[7,7])\n",
    "plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "#wordcloud.to_file(\"reddit2.png\")\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}