{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from utils import *\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = '/Users/chenjianyu/Library/Mobile Documents/com~apple~CloudDocs/SMU/SMU Module Materials/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_media_data_folder_paths = [\n",
    "    f'{parent_path}/Data/Hardwarezone Data/Cleaned Data', \n",
    "    f'{parent_path}/Data/Twitter Data/Cleaned Data/Policies/Combined',\n",
    "    f'{parent_path}/Data/Facebook Data/Cleaned Data/Policies/Combined',\n",
    "    f'{parent_path}/Data/Instagram Data/Cleaned Data/Policies/Combined',\n",
    "    f'{parent_path}/Data/Reddit Data/Cleaned Data/Policies/Combined',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy_data(policy, folders):\n",
    "    frames = []\n",
    "    for folder in folders:\n",
    "        files = [file for file in os.listdir(folder) if file.endswith('.csv')]\n",
    "        for file in files:\n",
    "            if policy.lower() in file.lower():\n",
    "                df = pd.read_csv(f'{folder}/{file}')\n",
    "                df = df[['Comments', 'Comment Datetime', 'actionable', 'valuable']]\n",
    "                frames.append(df)\n",
    "                break\n",
    "    final_df = pd.concat(frames, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "def corpus2docs(df):\n",
    "    docs1 = [TweetTokenizer().tokenize(comment) for comment in df['Comments']]\n",
    "    docs2 = [[w.lower() for w in doc] for doc in docs1]\n",
    "    docs3 = [[w for w in doc if re.search('^[a-z]+$', w)] for doc in docs2]\n",
    "    docs4 = [[w for w in doc if w not in stop_list] for doc in docs3]\n",
    "    return docs4\n",
    "\n",
    "def docs2vecs(docs, dic):\n",
    "    vecs = [dic.doc2bow(doc) for doc in docs]\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_policy_data('stay home notice', social_media_data_folder_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuable_comments = get_valuable_comments(df)\n",
    "actionable_comments = get_actionable_comments(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "366\n105\n1582\n"
     ]
    }
   ],
   "source": [
    "print(len(valuable_comments))\n",
    "print(len(actionable_comments))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuable_docs = corpus2docs(valuable_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuable_dic = gensim.corpora.Dictionary(valuable_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuable_vecs = docs2vecs(valuable_docs, valuable_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "lda_shn = gensim.models.ldamodel.LdaModel(corpus=valuable_vecs, id2word=valuable_dic, num_topics=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0, '0.008*\"shn\" + 0.006*\"also\" + 0.006*\"covid\" + 0.005*\"get\" + 0.005*\"singapore\" + 0.005*\"need\" + 0.005*\"back\" + 0.004*\"country\" + 0.004*\"day\" + 0.004*\"hotel\" + 0.004*\"like\" + 0.004*\"days\" + 0.004*\"said\" + 0.003*\"people\" + 0.003*\"case\" + 0.003*\"testing\" + 0.003*\"mr\" + 0.003*\"cases\" + 0.003*\"tests\" + 0.003*\"still\"')\n",
      "(1, '0.014*\"shn\" + 0.010*\"test\" + 0.010*\"case\" + 0.009*\"days\" + 0.007*\"covid\" + 0.007*\"singapore\" + 0.007*\"back\" + 0.007*\"positive\" + 0.006*\"infection\" + 0.006*\"cases\" + 0.006*\"tested\" + 0.006*\"also\" + 0.006*\"still\" + 0.006*\"community\" + 0.005*\"january\" + 0.005*\"people\" + 0.004*\"like\" + 0.004*\"quarantine\" + 0.004*\"result\" + 0.004*\"one\"')\n",
      "(2, '0.011*\"covid\" + 0.009*\"singapore\" + 0.008*\"people\" + 0.007*\"cases\" + 0.007*\"virus\" + 0.006*\"case\" + 0.006*\"shn\" + 0.006*\"community\" + 0.005*\"also\" + 0.005*\"infection\" + 0.005*\"one\" + 0.005*\"infected\" + 0.005*\"test\" + 0.004*\"positive\" + 0.004*\"day\" + 0.004*\"mask\" + 0.004*\"work\" + 0.004*\"would\" + 0.004*\"back\" + 0.004*\"leave\"')\n",
      "(3, '0.011*\"singapore\" + 0.009*\"shn\" + 0.008*\"people\" + 0.006*\"back\" + 0.006*\"go\" + 0.005*\"come\" + 0.004*\"days\" + 0.004*\"also\" + 0.004*\"got\" + 0.004*\"get\" + 0.004*\"sg\" + 0.004*\"think\" + 0.004*\"without\" + 0.004*\"cases\" + 0.004*\"virus\" + 0.003*\"hotel\" + 0.003*\"wrote\" + 0.003*\"may\" + 0.003*\"home\" + 0.003*\"would\"')\n",
      "(4, '0.013*\"shn\" + 0.009*\"cases\" + 0.009*\"people\" + 0.007*\"also\" + 0.006*\"covid\" + 0.006*\"like\" + 0.005*\"singapore\" + 0.005*\"get\" + 0.004*\"virus\" + 0.004*\"well\" + 0.004*\"know\" + 0.004*\"infected\" + 0.004*\"since\" + 0.004*\"still\" + 0.004*\"community\" + 0.004*\"wrote\" + 0.003*\"even\" + 0.003*\"us\" + 0.003*\"said\" + 0.003*\"say\"')\n",
      "(5, '0.014*\"covid\" + 0.014*\"test\" + 0.013*\"singapore\" + 0.011*\"case\" + 0.011*\"shn\" + 0.011*\"positive\" + 0.009*\"back\" + 0.007*\"days\" + 0.007*\"cases\" + 0.007*\"infection\" + 0.007*\"also\" + 0.007*\"tested\" + 0.006*\"january\" + 0.006*\"negative\" + 0.005*\"day\" + 0.005*\"likely\" + 0.005*\"february\" + 0.005*\"result\" + 0.005*\"community\" + 0.004*\"came\"')\n",
      "(6, '0.012*\"singapore\" + 0.011*\"covid\" + 0.011*\"case\" + 0.009*\"shn\" + 0.007*\"test\" + 0.007*\"back\" + 0.007*\"said\" + 0.006*\"cases\" + 0.005*\"people\" + 0.005*\"stay\" + 0.005*\"day\" + 0.005*\"get\" + 0.005*\"days\" + 0.005*\"also\" + 0.004*\"community\" + 0.004*\"quarantine\" + 0.004*\"moh\" + 0.004*\"infection\" + 0.004*\"need\" + 0.004*\"home\"')\n",
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "topics = lda_shn.show_topics(7, 20)\n",
    "\n",
    "for i in range(0, 7):\n",
    "    print(topics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "visual= pyLDAvis.gensim.prepare(lda_shn, valuable_vecs, valuable_dic)\n",
    "pyLDAvis.save_html(visual, \"topic_viz.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}