{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# text preprocessing\n",
    "from nltk import word_tokenize, TweetTokenizer, sent_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis.gensim\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# plots and metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# feature extraction / vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# save and load a file\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "parent_path = '/Users/chenjianyu/Library/Mobile Documents/com~apple~CloudDocs/SMU/SMU Module Materials/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "social_media_data_folder_paths = [\n",
    "    f'{parent_path}/Data/Hardwarezone Data/Cleaned Data', \n",
    "    f'{parent_path}/Data/Twitter Data/Cleaned Data/Policies/Combined',\n",
    "    f'{parent_path}/Data/Facebook Data/Cleaned Data/Policies/Combined',\n",
    "    f'{parent_path}/Data/Instagram Data/Cleaned Data/Policies/Combined',\n",
    "    f'{parent_path}/Data/Reddit Data/Cleaned Data/Policies/Combined',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def get_opinions(df):\n",
    "    return df[df['Textblob_subjectivity_score'] >= 0.5]\n",
    "\n",
    "def classify_emotions(df):\n",
    "    emotions = []\n",
    "    for row in df['Sentences']:\n",
    "        emotion = emotions_clf.predict([row])\n",
    "        emotions.append(emotion[0])\n",
    "    df['Emotions'] = emotions\n",
    "    return df\n",
    "\n",
    "def get_policy_data(policy, folders):\n",
    "    frames = []\n",
    "    for folder in folders:\n",
    "        files = [file for file in os.listdir(folder) if file.endswith('.csv')]\n",
    "        for file in files:\n",
    "            if policy.lower() in file.lower():\n",
    "                df = pd.read_csv(f'{folder}/{file}')\n",
    "                df = df[['Comments', 'Comment Datetime', 'actionable', 'valuable']]\n",
    "                frames.append(df)\n",
    "                print(True)\n",
    "                break\n",
    "    final_df = pd.concat(frames, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "def get_vader_sentiment(df, comment_header):\n",
    "    # df = pd.read_csv(file_path)\n",
    "    vader_analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "    vader_neg_sentiment = []\n",
    "    vader_neu_sentiment = []\n",
    "    vader_pos_sentiment = []\n",
    "    vader_compound_sentiment = []\n",
    "\n",
    "    for row in df[comment_header]:\n",
    "        score = vader_analyser.polarity_scores(row)\n",
    "\n",
    "        vader_neg_sentiment.append(score['neg'])\n",
    "        vader_neu_sentiment.append(score['neu'])\n",
    "        vader_pos_sentiment.append(score['pos'])\n",
    "        vader_compound_sentiment.append(score['compound'])\n",
    "    \n",
    "    df['Vader_neg_score'] = vader_neg_sentiment\n",
    "    df['Vader_neu_score'] = vader_neu_sentiment\n",
    "    df['Vader_pos_score'] = vader_pos_sentiment\n",
    "    df['Vader_compound_score'] = vader_compound_sentiment\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_textblob_sentiment(df, comment_header):\n",
    "    \n",
    "    # df = pd.read_csv(file_path)\n",
    "\n",
    "    polarity_scores = []\n",
    "    subjectivity_scores = []\n",
    "\n",
    "    for row in df[comment_header]:\n",
    "        analysis = TextBlob(row)\n",
    "        polarity_scores.append(analysis.sentiment.polarity)\n",
    "        subjectivity_scores.append(analysis.sentiment.subjectivity)\n",
    "    \n",
    "    df['Textblob_polarity_score'] = polarity_scores\n",
    "    df['Textblob_subjectivity_score'] = subjectivity_scores\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_actionable_comments(df, label = 1):\n",
    "    # df = pd.read_csv(file_path)\n",
    "    actionable_comments = df[df['actionable'] == label]\n",
    "\n",
    "    return actionable_comments\n",
    "\n",
    "def get_valuable_comments(df, label = 1.0):\n",
    "    # df = pd.read_csv(file_path)\n",
    "    valuable_comments = df[df['valuable'] == label]\n",
    "\n",
    "    return valuable_comments\n",
    "\n",
    "def sent_tokenize_then_to_df(df):\n",
    "    sentences_dict = {'Sentences': [], 'Comment Datetime': []}\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        sentences = sent_tokenize(df['Comments'].iloc[i])\n",
    "        for sent in sentences:\n",
    "            sentences_dict['Sentences'].append(sent)\n",
    "            sentences_dict['Comment Datetime'].append(df['Comment Datetime'].iloc[i])\n",
    "\n",
    "    final_df = pd.DataFrame(sentences_dict)\n",
    "    final_df.drop_duplicates(subset=['Sentences'], inplace=True)\n",
    "    final_df.reset_index(inplace=True)\n",
    "    return final_df"
   ]
  },
  {
   "source": [
    "# Circuit Breaker"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "policies = ['circuit breaker', 'tracetogether', 'foreign worker', 'social distancing', 'economic measures', 'vaccination', 'mask']\n",
    "names = ['total_comments', 'valuable_sentiments', 'actionable_sentiments', 'valuable_opinions', 'actionable_opinions', 'valuable_pos', 'valuable_neg', 'valuable_anger', 'valuable_joy', 'valuable_sad', 'valuable_fear', 'valuable_neu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for policy in policies:\n",
    "    ind = 0\n",
    "    cb_df = get_policy_data(policy, social_media_data_folder_paths) ##\n",
    "    cb_df.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1\n",
    "\n",
    "    cb_valuable_comments = get_valuable_comments(cb_df)\n",
    "    cb_valuable_comments.reset_index(inplace=True)\n",
    "\n",
    "    cb_actionable_comments = get_actionable_comments(cb_df)\n",
    "    cb_actionable_comments.reset_index(inplace=True)\n",
    "\n",
    "    cb_valuable_sent = sent_tokenize_then_to_df(cb_valuable_comments)\n",
    "    cb_actionable_sent = sent_tokenize_then_to_df(cb_actionable_comments)\n",
    "\n",
    "    cb_valuable_polarity = get_textblob_sentiment(cb_valuable_sent, 'Sentences')\n",
    "    cb_actionable_polarity = get_textblob_sentiment(cb_actionable_sent, 'Sentences')\n",
    "\n",
    "    cb_valuable_sentiment = get_vader_sentiment(cb_valuable_polarity, 'Sentences')\n",
    "    cb_actionable_sentiment = get_vader_sentiment(cb_actionable_polarity, 'Sentences')\n",
    "\n",
    "    cb_valuable_emotions = classify_emotions(cb_valuable_sentiment) ##\n",
    "    cb_valuable_emotions.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1\n",
    "    cb_actionable_emotions = classify_emotions(cb_actionable_sentiment) ##\n",
    "    cb_actionable_emotions.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1\n",
    "\n",
    "    cb_valuable_opinions = get_opinions(cb_valuable_emotions) ##\n",
    "    cb_valuable_opinions.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1\n",
    "    cb_actionable_opinions = get_opinions(cb_actionable_emotions) ##\n",
    "    cb_actionable_opinions.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1\n",
    "\n",
    "    cb_val_pos_opinions =     cb_valuable_opinions[cb_valuable_opinions['Vader_compound_score'] >= 0.1]\n",
    "    cb_val_pos_opinions.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1\n",
    "    cb_val_neg_opinions =     cb_valuable_opinions[cb_valuable_opinions['Vader_compound_score'] <= -0.1]\n",
    "    cb_val_neg_opinions.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1\n",
    "    cb_val_anger_opinions =   cb_valuable_opinions[cb_valuable_opinions['Emotions'] <= 'anger']\n",
    "    cb_val_anger_opinions.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1\n",
    "    cb_val_joy_opinions =     cb_valuable_opinions[cb_valuable_opinions['Emotions'] <= 'joy']\n",
    "    cb_val_joy_opinions.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1\n",
    "    cb_val_sadness_opinions = cb_valuable_opinions[cb_valuable_opinions['Emotions'] <= 'sadness']\n",
    "    cb_val_sadness_opinions.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1\n",
    "    cb_val_fear_opinions =    cb_valuable_opinions[cb_valuable_opinions['Emotions'] <= 'fear']\n",
    "    cb_val_fear_opinions.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1\n",
    "    cb_val_neutral_opinions = cb_valuable_opinions[cb_valuable_opinions['Emotions'] <= 'neutral']\n",
    "    cb_val_neutral_opinions.to_csv(f'{policy}_{names[ind]}.csv')\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_df.to_csv('circuit_breaker_total_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/data_train.csv')\n",
    "df_test = pd.read_csv('data/data_test.csv')\n",
    "\n",
    "X_train = df_train.Text\n",
    "X_test = df_test.Text\n",
    "\n",
    "y_train = df_train.Emotion\n",
    "y_test = df_test.Emotion\n",
    "\n",
    "class_names = ['joy', 'sadness', 'anger', 'neutral', 'fear']\n",
    "data = pd.concat([df_train, df_test])\n",
    "\n",
    "# print('size of training set: %s' % (len(df_train['Text'])))\n",
    "# print('size of validation set: %s' % (len(df_test['Text'])))\n",
    "# print(data.Emotion.value_counts())\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_tokenize(data):    \n",
    "\n",
    "    #remove html markup\n",
    "    data = re.sub(\"(<.*?>)\", \"\", data)\n",
    "\n",
    "    #remove urls\n",
    "    data = re.sub(r'http\\S+', '', data)\n",
    "    \n",
    "    #remove hashtags and @names\n",
    "    data= re.sub(r\"(#[\\d\\w\\.]+)\", '', data)\n",
    "    data= re.sub(r\"(@[\\d\\w\\.]+)\", '', data)\n",
    "\n",
    "    #remove punctuation and non-ascii digits\n",
    "    data = re.sub(\"(\\\\W|\\\\d)\", \" \", data)\n",
    "    \n",
    "    #remove whitespace\n",
    "    data = data.strip()\n",
    "    \n",
    "    # tokenization with nltk\n",
    "    data = word_tokenize(data)\n",
    "    \n",
    "    # stemming with nltk\n",
    "    porter = PorterStemmer()\n",
    "    stem_data = [porter.stem(word) for word in data]\n",
    "        \n",
    "    return stem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF, unigrams and bigrams\n",
    "vect = TfidfVectorizer(tokenizer=preprocess_and_tokenize, sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "\n",
    "# fit on our complete corpus\n",
    "vect.fit_transform(data.Text)\n",
    "\n",
    "# transform testing and training datasets to vectors\n",
    "X_train_vect = vect.transform(X_train)\n",
    "X_test_vect = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(tol=1e-05)\n",
    "svc.fit(X_train_vect, y_train)\n",
    "\n",
    "svm_pred = svc.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "svm_model = Pipeline([('tfidf', vect),('clf', svc),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "emotions_clf_filename = 'tfidf_svm.sav'\n",
    "pickle.dump(svm_model, open(emotions_clf_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['anger'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "emotions_clf = pickle.load(open('tfidf_svm.sav', 'rb'))\n",
    "\n",
    "message = 'delivery was hour late and my pizza is cold!' \n",
    "emotions_clf.predict([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Generating sent tokenized comments for all comments in a policy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/chenjianyu/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "policies = ['circuit breaker', 'tracetogether', 'foreign worker', 'social distancing', 'economic measures', 'vaccination', 'mask']\n",
    "for policy in policies:\n",
    "    cb_df = get_policy_data(policy, social_media_data_folder_paths) ##\n",
    "    cb_sent = sent_tokenize_then_to_df(cb_df)\n",
    "    cb_sent.to_csv(f'{policy}_all_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}