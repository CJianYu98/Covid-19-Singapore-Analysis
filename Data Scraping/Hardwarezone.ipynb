{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Forums and Subforums\n",
    "Do not need to run this section if have the list of subforums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getForums(site_url):\n",
    "    col=['forum','subforum','forum_url']\n",
    "    top_df = pd.DataFrame(columns=col)\n",
    "    r = re.get(site_url)\n",
    "    page = r.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    for element in soup.find_all('td', {\"class\": \"alt1Active\"}):\n",
    "        forum_title_div = element.div\n",
    "        forum_link = forum_title_div.a\n",
    "        forum_url = site_url + forum_link['href']\n",
    "        if('.com' in forum_link['href']):\n",
    "            forum_url = forum_link['href']\n",
    "        forum_title = forum_link.strong.string\n",
    "        subforum = ''\n",
    "\n",
    "        row = pd.DataFrame([[forum_title,subforum,forum_url]], columns=col)\n",
    "        if(len(top_df)==0):\n",
    "            top_df = row\n",
    "        else:\n",
    "            top_df = top_df.append(row, ignore_index=True) #df.append doesn't work inplace\n",
    "\n",
    "        for child in element.find_all('div', {\"style\" : \"margin-top:6px\"}):\n",
    "            if child.find('strong') != None: #has a Sub-Forums section\n",
    "                for subforum_link in child.find_all('a'):\n",
    "                    subforum = subforum_link.contents[0]\n",
    "                    forum_url = site_url + subforum_link['href']\n",
    "                    if('.com' in subforum_link['href']):\n",
    "                        forum_url = subforum_link['href']\n",
    "                    row = pd.DataFrame([[forum_title,subforum,forum_url]], columns=col)\n",
    "                    if(len(top_df)==0):\n",
    "                        top_df = row\n",
    "                    else:\n",
    "                        top_df = top_df.append(row, ignore_index=True) #df.append doesn't work inplace\n",
    "    return top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_url = 'https://forums.hardwarezone.com.sg'\n",
    "hwz = getForums(site_url)\n",
    "print(len(hwz))\n",
    "hwz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwz.to_csv('hwz_subforums.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getThreads(forum_url, keywords):\n",
    "    lastForumPage = False\n",
    "    forum_cols = ['thread', 'datetime','thread_url']\n",
    "    forum_df = pd.DataFrame(columns=forum_cols)\n",
    "    forum_page_url = forum_url\n",
    "    \n",
    "    while(not lastForumPage):\n",
    "        r2 = re.get(forum_page_url)\n",
    "        forum_page = r2.text\n",
    "        forum_page_soup = BeautifulSoup(forum_page, 'html.parser')\n",
    "\n",
    "        if (forum_page_soup.find('a', text='Next ‚Ä∫') == None):\n",
    "            lastForumPage = True\n",
    "        else:\n",
    "            forum_page_url = site_url + forum_page_soup.find('a', text='Next ‚Ä∫')['href']\n",
    "        \n",
    "        forum_num = subforum_url.strip('/').split('-')\n",
    "        forum_num = forum_num[-1]\n",
    "        \n",
    "        thread_body = forum_page_soup.find('tbody',{'id': f'threadbits_forum_{forum_num}'})\n",
    "        \n",
    "        for thread in thread_body:\n",
    "            if len(thread) == 1: \n",
    "                continue\n",
    "            try: \n",
    "\n",
    "                # Retrieve Date \n",
    "                date_block = thread.find_all('td', class_ = \"alt2\")[1].find('div', class_= \"smallfont\" ).contents\n",
    "                date = date_block[0].strip()\n",
    "                if date == 'Yesterday' : \n",
    "                    date = (datetime.date.today() - datetime.timedelta(1)).strftime('%Y-%m-%d')\n",
    "                elif date == 'Today': \n",
    "                    date = datetime.date.today().strftime('%Y-%m-%d')\n",
    "                    \n",
    "                if '2020' not in date and '2021' not in date: \n",
    "                    if 'class=\"hwz-sticky\"' not in str(thread):\n",
    "                        return forum_df   # Return forum_df with threads from 2020 onwards\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                # Retrieve Thread Title\n",
    "                title = thread.find('a', {\"id\": lambda x: x and 'thread_title_' in x}).contents[0]\n",
    "                for k in keywords: \n",
    "                    if k in title.lower():\n",
    "\n",
    "                        print(title)\n",
    "\n",
    "                        # Retrieve Time\n",
    "                        time = thread.find('span', class_ = 'time').text\n",
    "\n",
    "                        # Retrieve Date and Time\n",
    "                        date_time = date + ' ' + time\n",
    "\n",
    "                        # Retrieve Thread Url           \n",
    "                        url = site_url + thread.find('a', {\"id\": lambda x: x and 'thread_title_' in x})['href']        \n",
    "\n",
    "                        row = pd.DataFrame([[title, date_time, url]], columns=forum_cols)\n",
    "                        if(len(forum_df)==0):\n",
    "                            forum_df = row\n",
    "                        else:\n",
    "                            forum_df = forum_df.append(row, ignore_index=True) #df.append doesn't work inplace\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    forum_df.drop_duplicates()\n",
    "                \n",
    "    return forum_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of keywords\n",
    "As of 26/02/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_tracetogether = ['tracetogether', 'trace together', 'contact tracing', 'contacttracing', 'tokens', 'breach of privacy', \n",
    "                    'criminal data', 'bluetrace', 'opentrace', 'nric', 'ministry of heath', 'govtech'\n",
    "                    'government technology agency', 'smart nation', 'vivian balakrishnan', 'bluetooth', 'lawrence wong', \n",
    "                    \"singapore's people party\", 'criminal procedure code', 'surveillance', 'privacy', 'eugene tan']\n",
    "\n",
    "kw_safeentry = ['safeentry', 'safe entry']\n",
    "\n",
    "kw_vaccination = ['vaccine', 'vaccination', 'pfizer', 'moderna', 'vaccine side effects', 'sinovac']\n",
    "\n",
    "kw_foreign_workers = ['foreign worker', 'foreign worker dorm', 'foreign worker dormitories', 'dorm', 'dormitories', \n",
    "                      'swab testing facilities', 'dormitory cluster', 'mom', 'ministry of manpower',\n",
    "                      'community care facility', 'community care facilities', 'josephine teo', 'migrant workers', \n",
    "                      'makeshift dormitories']\n",
    "\n",
    "kw_social_distancing = ['social distancing', 'safe distancing', 'group size limit', '1m apart', '2m apart', 'cny', \n",
    "                        'chinese new year', 'safe distancing ambassador', 'social distancing ambassador', \n",
    "                        'physical contact', 'face-to-face']\n",
    "\n",
    "kw_circuit_breaker = ['circuit breaker', 'cb', 'panic buying', 'hoarding', 'quarantine', 'lockdown', 'travel bubble',\n",
    "                      'travel restrictions', 'work from home', 'wfh', 'telecommuting', 'remote working', 'home based learning', \n",
    "                      'hbl', 'stay home order', \"mcdonald's\", 'haircut', 'hair salon', 'hair dressers', 'barber', 'gathering', \n",
    "                      'mass gathering', 'places of worship', 'place of worship', 'marriage', 'empty streets', 'airplane crew', \n",
    "                      'stay home', 'airline crew', 'sia', 'reopening', 'stewardess', 'staycation', 'house visit', 'gather', \n",
    "                      'extension']\n",
    "\n",
    "kw_economic_measures = ['government spending', 'budget', 'heng swee keat', 'economy', 'jobs support scheme', 'stimulus package', \n",
    "                        'support fund', 'stablisation and support package', 'assurance package', 'resilience budget', 'support package', \n",
    "                        'business support', 'co-funding', 'food service', 'solidarity budget', 'fortitude budget', 'wage subsidies', \n",
    "                        'jobs and skills package', 'singaporedediscovers', 'financial support', 'payouts', 'support grant', \n",
    "                        'temporary relief refund']\n",
    "\n",
    "kw_general = ['phase 1', 'phase 2', 'phase 3', 'coronavirus', 'corona', 'covid', 'covid19', 'pandemic', 'healthcare', 'hospital', \n",
    "              'frontline workers', 'surgical face masks', 'face mask', 'masks', 'mask-wearing', 'hand sanitizer', 'clusters',\n",
    "              'doscorn', 'stay home notice', 'shn', 'covid taskforce', 'swab test', 'Gan Kim Yong', 'local case',\n",
    "              'sgunited', 'essential workers', 'non-essential workers', 'essential business', 'non-essential business', \n",
    "              'mental health']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting threads based on policy/keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a folder named \"Threads\" in the current directory'''\n",
    "\n",
    "def threads_tracetogether(subforum, subforum_url, keywords): \n",
    "    threads = getThreads(subforum_url, keywords)\n",
    "    filepath = os.path.join('Threads', f'{subforum}_tracetogether_threads.csv')\n",
    "    threads.to_csv(filepath, encoding = 'utf-8', index = False)\n",
    "    return threads.info()\n",
    "\n",
    "def threads_safeentry(subforum, subforum_url, keywords): \n",
    "    threads = getThreads(subforum_url, keywords)\n",
    "    filepath = os.path.join('Threads', f'{subforum}_safeentry_threads.csv')\n",
    "    threads.to_csv(filepath, encoding = 'utf-8', index = False)\n",
    "    return threads.info()\n",
    "\n",
    "def threads_vaccination(subforum, subforum_url, keywords): \n",
    "    threads = getThreads(subforum_url, keywords)\n",
    "    filepath = os.path.join('Threads', f'{subforum}_vaccination_threads.csv')\n",
    "    threads.to_csv(filepath, encoding = 'utf-8', index = False)\n",
    "    return threads.info()\n",
    "\n",
    "def threads_foreign_workers(subforum, subforum_url, keywords): \n",
    "    threads = getThreads(subforum_url, keywords)\n",
    "    filepath = os.path.join('Threads', f'{subforum}_foreign_workers_threads.csv')\n",
    "    threads.to_csv(filepath, encoding = 'utf-8', index = False)\n",
    "    return threads.info()\n",
    "\n",
    "def threads_social_distancing(subforum, subforum_url, keywords): \n",
    "    threads = getThreads(subforum_url, keywords)\n",
    "    filepath = os.path.join('Threads', f'{subforum}_social_distancing_threads.csv')\n",
    "    threads.to_csv(filepath, encoding = 'utf-8', index = False)\n",
    "    return threads.info()\n",
    "\n",
    "def threads_circuit_breaker(subforum, subforum_url, keywords): \n",
    "    threads = getThreads(subforum_url, keywords)\n",
    "    filepath = os.path.join('Threads', f'{subforum}_circuit_breaker_threads.csv')\n",
    "    threads.to_csv(filepath, encoding = 'utf-8', index = False)\n",
    "    return threads.info()\n",
    "\n",
    "def threads_economic_measures(subforum, subforum_url, keywords): \n",
    "    threads = getThreads(subforum_url, keywords)\n",
    "    filepath = os.path.join('Threads', f'{subforum}_economic_measures_threads.csv')\n",
    "    threads.to_csv(filepath, encoding = 'utf-8', index = False)\n",
    "    return threads.info()\n",
    "\n",
    "def threads_general(subforum, subforum_url, keywords): \n",
    "    threads = getThreads(subforum_url, keywords)\n",
    "    filepath = os.path.join('Threads', f'{subforum}_general_threads.csv')\n",
    "    threads.to_csv(filepath, encoding = 'utf-8', index = False)\n",
    "    return threads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communist China Exploits Gaps in US Military¬óRebeccah Heinrichs\n",
      "Picture privacy.\n",
      "Somebody stole my NRIC number???\n",
      "[158th]Lawrence Wong:Doctors/experts requested MOM to advise employers not to send FW for testing!\n",
      "COVID-19 contact tracing ¬ëabsolutely essential¬í; wearable TraceTogether tokens to be rolled out in J\n",
      "COVID-19 contact tracing ¬ëabsolutely essential¬í; wearable TraceTogether tokens to be rolled out in J\n",
      "COVID-19 contact tracing ¬ëabsolutely essential¬í; wearable TraceTogether tokens to be rolled out in J\n",
      "[BREAK] Contact tracing devices to be rolled out 'soon', distributed to everyone in Singapore\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 3 columns):\n",
      "thread        8 non-null object\n",
      "datetime      8 non-null object\n",
      "thread_url    8 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 320.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 3 columns):\n",
      "thread        0 non-null object\n",
      "datetime      0 non-null object\n",
      "thread_url    0 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 0.0+ bytes\n",
      "(Breaking) China's experimental COVID-19 vaccine appears safe: Study\n",
      "CCP tok tiong, vaccine cost 300 RMB in tiongkok, sold to Brazil for 2 USD\n",
      "Breaking: Khairy: Malaysia might get access to Covid-19 vaccine from China\n",
      "[CNN] China makes $1bn loan for vaccine access; Latin America üëè üëè üëè\n",
      "China has developed a inactivated vaccine BBIBP-CorV to fight Covid 19\n",
      "[Breaking] US says Tiongkok Hacking & Stealing its Wuhan Virus Vaccine Research!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 3 columns):\n",
      "thread        6 non-null object\n",
      "datetime      6 non-null object\n",
      "thread_url    6 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 272.0+ bytes\n",
      "MOM: \"Same Nationality\" PMET majority in Bank and Wealth Management Firm\n",
      "BREAKING: MOM to raise salary criteria for EP & S Pass\n",
      "[Official MOM's Website - Jul 2020] S'pore Has Let in the Most No. of Foreign PMETs in Its History!!\n",
      "[GVGT] Jamus Lim and Josephine Teo debate effectiveness of Singapore's Employment, S Pass measures\n",
      "MOM won't hesitate to hold employers discriminating against Singaporeans...\n",
      "GPGT: Ho Jinx asked y'all not to assume the crowded or poor living conditions in the dormitory\n",
      "[Breaking] 290m Migrant Workers risk retrenchment as Factories & Jobs flee Tiongkok\n",
      "Dorms to be cleared by 7 Aug? Here are lists of 560 dorms that are yet to be cleared\n",
      "MOM and ICA Please EXPLAIN WHY SO MANY imported india cases!!\n",
      "Manpower Minister Josephine Teo: What people want for me is a listening ear and a willing heart\n",
      "Would chiu vote for Josephine Teo if she is in a SMC?\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "site_url = 'https://forums.hardwarezone.com.sg'\n",
    "\n",
    "# manually key in subforum_url & subforum\n",
    "subforum_url = 'https://forums.hardwarezone.com.sg/current-affairs-lounge-17/'\n",
    "subforum = 'current-affairs-lounge'\n",
    "\n",
    "# Change the directory\n",
    "os.chdir(r\"C:/Users/Gi Han/Documents/SMT203 Computational Social Science/Hardwarezone\")\n",
    "\n",
    "threads_tracetogether(subforum, subforum_url, kw_tracetogether)\n",
    "threads_safeentry(subforum, subforum_url, kw_safeentry)\n",
    "threads_vaccination(subforum, subforum_url, kw_vaccination)\n",
    "threads_foreign_workers(subforum, subforum_url, kw_foreign_workers)\n",
    "# threads_social_distancing(subforum, subforum_url, kw_social_distancing)\n",
    "# threads_circuit_breaker(subforum, subforum_url, kw_circuit_breaker)\n",
    "# threads_economic_measures(subforum, subforum_url, kw_economic_measures)\n",
    "# threads_general(subforum, subforum_url, kw_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Posts - all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getPosts(thread_url):\n",
    "    #print(thread_url)\n",
    "    lastThreadPage = False\n",
    "    thread_cols = ['post_id','timestamp', 'post_text']\n",
    "    thread_df = pd.DataFrame(columns=thread_cols)\n",
    "    thread_page_url = thread_url\n",
    "    \n",
    "    count = 0\n",
    "    while(not lastThreadPage):\n",
    "        #print(thread_page_url)\n",
    "        r3 = re.get(thread_page_url)\n",
    "        thread_page = r3.text\n",
    "        thread_page_soup = BeautifulSoup(thread_page, 'html.parser')\n",
    "\n",
    "        if (thread_page_soup.find('a', text='Next ‚Ä∫') == None):\n",
    "            lastThreadPage = True\n",
    "        else:\n",
    "            thread_page_url = site_url + thread_page_soup.find('a', text='Next ‚Ä∫')['href']\n",
    "\n",
    "        thread_page_posts = thread_page_soup.find('div', {'id': 'posts'})\n",
    "                \n",
    "        try: \n",
    "            for post in thread_page_posts.find_all('div', {'class': 'post-wrapper'}):\n",
    "                \n",
    "                # Retrieve Date & Time\n",
    "                datetime_raw = post.find('a', {'name': lambda x: x and x.find('post') == 0}).nextSibling.strip()\n",
    "                date = datetime_raw.split(',')[0]\n",
    "                \n",
    "                if date == 'Yesterday' : \n",
    "                    date = (datetime.date.today() - datetime.timedelta(1)).strftime('%Y-%m-%d')\n",
    "                elif date == 'Today': \n",
    "                    date = datetime.date.today().strftime('%Y-%m-%d')\n",
    "                    \n",
    "                time = datetime_raw.split(',')[1]\n",
    "                date_time = date + ' ' + time\n",
    "                \n",
    "                # Retrieve Post Text\n",
    "                post_text = \"\"\n",
    "                try:\n",
    "                    post_text = post.find('div', {'class': 'post_message'}).get_text(' ', strip=True)\n",
    "                except AttributeError as e: \n",
    "                    pass\n",
    "                \n",
    "                # Retrieve Post ID\n",
    "                post_id = int(post.find('a', {'id': lambda x: x and 'postcount' in x, 'target': 'new'})['id'].lstrip('postcount'))\n",
    "                \n",
    "                row = pd.DataFrame([[ post_id, date_time, post_text]], columns=thread_cols)\n",
    "                if(len(thread_df)==0):\n",
    "                    thread_df = row\n",
    "                else:\n",
    "                    thread_df = thread_df.append(row, ignore_index=True) #df.append doesn't work inplace\n",
    "        except:\n",
    "            row = pd.DataFrame([[np.nan, np.nan, \"\"]], columns=thread_cols) #posts missing, thread may have been deleted\n",
    "            if(len(thread_df)==0):\n",
    "                thread_df = row\n",
    "            else:\n",
    "                thread_df = thread_df.append(row, ignore_index=True) #df.append doesn't work inplace\n",
    "        \n",
    "    thread_df['post_text'] = thread_df['post_text'].map(lambda x: x.encode('unicode-escape').decode('utf-8'))\n",
    "    \n",
    "    thread_df.drop_duplicates()\n",
    "\n",
    "    return thread_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine posts with threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns posts for each thread in specified subforum and policy \n",
    "\n",
    "def post_threads(df):\n",
    "    new_df = pd.DataFrame(columns = ['thread', 'datetime','thread_url', 'post_id','post_timestamp', 'post_text'])\n",
    "    df_col = new_df.columns\n",
    "    \n",
    "    for index in df.index:\n",
    "        thread_url = df['thread_url'][index]\n",
    "        posts = getPosts(thread_url)\n",
    "        for p_index in posts.index:\n",
    "            row = pd.DataFrame([[df['thread'][index], df['datetime'][index], df['thread_url'][index], \n",
    "                                posts['post_id'][p_index], posts['timestamp'][p_index], posts['post_text'][p_index]]], \n",
    "                               columns = df_col)\n",
    "            new_df = new_df.append(row, ignore_index = True, sort = False)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eat-drink-man-woman_vaccination_threads.csv',\n",
       " 'Not Done',\n",
       " 'Post Retrieved',\n",
       " 'Posts']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.path.abspath('.')\n",
    "\n",
    "# Change the directory to the respective directory\n",
    "os.chdir(r\"./Threads/..\")\n",
    "\n",
    "files = os.listdir(cwd)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: eat-drink-man-woman_tracetogether_threads.csv\n",
      "Complete: eat-drink-man-woman_vaccination_threads.csv\n"
     ]
    }
   ],
   "source": [
    "'''Create a folder named \"Posts\" in the current directory'''\n",
    "\n",
    "site_url = 'https://forums.hardwarezone.com.sg'\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.csv'):\n",
    "        df = pd.read_csv(f'{file}')\n",
    "        new_df = post_threads(df)\n",
    "        filename = f'{file}'[:-11] + 'posts'\n",
    "        filepath = os.path.join('Posts', filename + '.csv')\n",
    "        new_df.to_csv(filepath, index = False)\n",
    "        print(f'Complete: {file}')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
