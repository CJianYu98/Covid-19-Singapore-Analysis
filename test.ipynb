{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'folder_path'\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df_list.append(df)\n",
    "\n",
    " output = pd.concat(df_list)\n",
    "\n",
    " output.to_csv('path') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text_split = re.split(\"\\\\', \\\\'\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Is the vaccine out already?\\', \"She doesn\\'t look like she wants to do this...\", \"Mine\\'s coming soon ! We need 60% vaccination to have herd immunity. let do it!\", \\'Lol'"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "text_split[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Data/Facebook Data/Cleaned Data/fb_merged_data.csv'\n",
    "folders = [folder for folder in os.listdir(path) if folder != '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    files = [file for file in os.listdir(f'{path}/{folder}') if file.endswith('.csv') and file != '.DS_Store']\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(f'{path}/{folder}/{file}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/Facebook Data/Cleaned Data/fb_merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Timestamp('2021-06-02 10:00:00')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df['date'][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Timestamp('2021-06-02 10:00:00')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df['date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Train suggestion labelled data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk import word_tokenize\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Suggestion Labelled Data/Suggestions_Student_labelled.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 2\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'Suggestion': {'Y': 1, np.nan: 0}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Suggestion Labelled Data/suggestions.txt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-370408c75599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Suggestion Labelled Data/suggestions.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Suggestion Labelled Data/suggestions.txt'"
     ]
    }
   ],
   "source": [
    "open('/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Suggestion Labelled Data/suggestions.txt', \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Suggestion Labelled Data/suggestions.txt', 'a') as f:\n",
    "\n",
    "    for row in df['Comment']:\n",
    "        f.write(str(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PlaintextCorpusReader('/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Suggestion Labelled Data/', '.+\\.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = corpus.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_lower = [w.lower() for w in docs]\n",
    "docs_alpha = [w for w in docs_lower if re.search('^[a-z]+$', w)]\n",
    "\n",
    "# Remove stop words.\n",
    "stop_list = stopwords.words('english')\n",
    "docs_stop = [w for w in docs_alpha if w not in stop_list]\n",
    "\n",
    "# Perform Porter stemming. Store in variable docs_stem\n",
    "stemmer = PorterStemmer()\n",
    "docs_stem = [stemmer.stem(w) for w in docs_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary([docs_stem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dictionary(982 unique tokens: ['aa', 'abl', 'absorb', 'accent', 'accept']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(columns=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: 'aa', 1: 'abl', 2: 'absorb', 3: 'accent', 4: 'accept', 5: 'accord', 6: 'accordingli', 7: 'account', 8: 'achiev', 9: 'across', 10: 'activ', 11: 'actual', 12: 'add', 13: 'address', 14: 'adequ', 15: 'adjust', 16: 'admit', 17: 'advanc', 18: 'advantag', 19: 'advic', 20: 'advoc', 21: 'affect', 22: 'agre', 23: 'akin', 24: 'algorithm', 25: 'alittl', 26: 'alloc', 27: 'allow', 28: 'alon', 29: 'along', 30: 'alot', 31: 'alreadi', 32: 'also', 33: 'although', 34: 'alway', 35: 'amaz', 36: 'among', 37: 'amount', 38: 'anal', 39: 'analog', 40: 'analys', 41: 'analysi', 42: 'anoth', 43: 'answer', 44: 'anyon', 45: 'anyth', 46: 'apart', 47: 'app', 48: 'appl', 49: 'appli', 50: 'applic', 51: 'appreci', 52: 'approach', 53: 'appropri', 54: 'area', 55: 'articul', 56: 'ask', 57: 'aspect', 58: 'assess', 59: 'assign', 60: 'associ', 61: 'assum', 62: 'assumpt', 63: 'attain', 64: 'attempt', 65: 'attend', 66: 'attent', 67: 'avail', 68: 'avenu', 69: 'away', 70: 'awesom', 71: 'back', 72: 'background', 73: 'bad', 74: 'balanc', 75: 'barrier', 76: 'base', 77: 'basic', 78: 'battlest', 79: 'bbm', 80: 'becom', 81: 'behind', 82: 'believ', 83: 'bell', 84: 'benefici', 85: 'benefit', 86: 'best', 87: 'better', 88: 'bit', 89: 'blown', 90: 'board', 91: 'boom', 92: 'bore', 93: 'bottleneck', 94: 'breadth', 95: 'break', 96: 'breakdown', 97: 'bridg', 98: 'bring', 99: 'broad', 100: 'build', 101: 'bulk', 102: 'busi', 103: 'c', 104: 'cabl', 105: 'cancel', 106: 'cannot', 107: 'care', 108: 'career', 109: 'case', 110: 'cat', 111: 'caus', 112: 'certain', 113: 'certainti', 114: 'challeng', 115: 'chang', 116: 'chapter', 117: 'check', 118: 'cheer', 119: 'choic', 120: 'chose', 121: 'chosen', 122: 'circumst', 123: 'clarif', 124: 'clarifi', 125: 'clariti', 126: 'class', 127: 'clear', 128: 'clearer', 129: 'clearli', 130: 'click', 131: 'client', 132: 'code', 133: 'coder', 134: 'cohort', 135: 'collabor', 136: 'come', 137: 'comfort', 138: 'commend', 139: 'commit', 140: 'common', 141: 'commun', 142: 'compani', 143: 'compar', 144: 'comparison', 145: 'compet', 146: 'competit', 147: 'complet', 148: 'complex', 149: 'compon', 150: 'compress', 151: 'compulsori', 152: 'comput', 153: 'con', 154: 'concept', 155: 'concern', 156: 'concis', 157: 'conclus', 158: 'concret', 159: 'conduct', 160: 'configur', 161: 'conflict', 162: 'confus', 163: 'congruent', 164: 'consid', 165: 'consider', 166: 'consolid', 167: 'constant', 168: 'constantli', 169: 'constraint', 170: 'construct', 171: 'consult', 172: 'consum', 173: 'contain', 174: 'conten', 175: 'content', 176: 'continu', 177: 'contribut', 178: 'control', 179: 'cool', 180: 'cope', 181: 'copi', 182: 'core', 183: 'correct', 184: 'could', 185: 'count', 186: 'cours', 187: 'coursd', 188: 'cover', 189: 'cramp', 190: 'creat', 191: 'credit', 192: 'criteria', 193: 'crowd', 194: 'crucial', 195: 'cu', 196: 'curios', 197: 'current', 198: 'curv', 199: 'cut', 200: 'cute', 201: 'daili', 202: 'data', 203: 'databas', 204: 'day', 205: 'deadlin', 206: 'deal', 207: 'decis', 208: 'dedic', 209: 'deep', 210: 'deeper', 211: 'definit', 212: 'deliv', 213: 'deliver', 214: 'deliveri', 215: 'demand', 216: 'demonstr', 217: 'deni', 218: 'depress', 219: 'depth', 220: 'descript', 221: 'design', 222: 'despit', 223: 'detail', 224: 'develop', 225: 'devot', 226: 'diagram', 227: 'didnt', 228: 'differ', 229: 'difficult', 230: 'difficulti', 231: 'direct', 232: 'disadvantag', 233: 'discourag', 234: 'discov', 235: 'discu', 236: 'discuss', 237: 'disk', 238: 'dislik', 239: 'dismiss', 240: 'disregard', 241: 'distinct', 242: 'dive', 243: 'divers', 244: 'dm', 245: 'doabl', 246: 'doesnt', 247: 'done', 248: 'dont', 249: 'doubt', 250: 'dr', 251: 'draggi', 252: 'dread', 253: 'dri', 254: 'drink', 255: 'due', 256: 'dull', 257: 'durat', 258: 'e', 259: 'earli', 260: 'earlier', 261: 'earth', 262: 'easi', 263: 'easier', 264: 'easili', 265: 'easygo', 266: 'effect', 267: 'effort', 268: 'either', 269: 'elabor', 270: 'em', 271: 'emphasi', 272: 'emphasis', 273: 'enabl', 274: 'encourag', 275: 'end', 276: 'energi', 277: 'enforc', 278: 'engag', 279: 'enjoy', 280: 'enlarg', 281: 'enough', 282: 'enrich', 283: 'ensur', 284: 'enterpris', 285: 'entertain', 286: 'enthusiasm', 287: 'enthusiast', 288: 'entir', 289: 'environ', 290: 'er', 291: 'esp', 292: 'especi', 293: 'etc', 294: 'etl', 295: 'even', 296: 'ever', 297: 'everi', 298: 'everyday', 299: 'everyon', 300: 'everyth', 301: 'exam', 302: 'exampl', 303: 'excel', 304: 'excit', 305: 'exercis', 306: 'exist', 307: 'expand', 308: 'expect', 309: 'experi', 310: 'experienc', 311: 'expertis', 312: 'explain', 313: 'explan', 314: 'explor', 315: 'exploratori', 316: 'expos', 317: 'extens', 318: 'extern', 319: 'extra', 320: 'extrem', 321: 'eye', 322: 'fa', 323: 'face', 324: 'facilit', 325: 'fact', 326: 'fair', 327: 'familiar', 328: 'far', 329: 'fast', 330: 'faster', 331: 'feasibl', 332: 'feedback', 333: 'feel', 334: 'felt', 335: 'field', 336: 'file', 337: 'final', 338: 'financ', 339: 'financi', 340: 'find', 341: 'fine', 342: 'first', 343: 'flawless', 344: 'flexibl', 345: 'flexsim', 346: 'fluffi', 347: 'focu', 348: 'focus', 349: 'folder', 350: 'follow', 351: 'forc', 352: 'forgett', 353: 'form', 354: 'formula', 355: 'found', 356: 'foundat', 357: 'frame', 358: 'frank', 359: 'free', 360: 'frequent', 361: 'friend', 362: 'friendli', 363: 'full', 364: 'fulli', 365: 'fun', 366: 'function', 367: 'fundament', 368: 'funni', 369: 'futur', 370: 'fyp', 371: 'g', 372: 'gain', 373: 'game', 374: 'garner', 375: 'gasp', 376: 'gather', 377: 'gd', 378: 'gener', 379: 'get', 380: 'give', 381: 'given', 382: 'glad', 383: 'go', 384: 'goal', 385: 'goe', 386: 'gone', 387: 'gonna', 388: 'good', 389: 'got', 390: 'grade', 391: 'grasp', 392: 'great', 393: 'greater', 394: 'greatli', 395: 'ground', 396: 'group', 397: 'guid', 398: 'guidanc', 399: 'guidelin', 400: 'half', 401: 'hand', 402: 'hard', 403: 'hardcor', 404: 'hardest', 405: 'hardli', 406: 'heartfelt', 407: 'heavi', 408: 'heavier', 409: 'heavili', 410: 'held', 411: 'hell', 412: 'help', 413: 'henc', 414: 'hesit', 415: 'high', 416: 'highli', 417: 'highlight', 418: 'holist', 419: 'home', 420: 'hope', 421: 'hour', 422: 'howev', 423: 'humor', 424: 'hve', 425: 'idea', 426: 'identifi', 427: 'illustr', 428: 'imag', 429: 'impart', 430: 'implement', 431: 'implic', 432: 'import', 433: 'importantli', 434: 'impress', 435: 'improv', 436: 'inadequ', 437: 'includ', 438: 'incorpor', 439: 'increas', 440: 'indic', 441: 'individu', 442: 'industri', 443: 'influenc', 444: 'inform', 445: 'inifinit', 446: 'initi', 447: 'insecur', 448: 'insid', 449: 'insight', 450: 'instead', 451: 'instruct', 452: 'instructor', 453: 'insuffici', 454: 'intens', 455: 'interact', 456: 'interactv', 457: 'interest', 458: 'interim', 459: 'intern', 460: 'internship', 461: 'introduc', 462: 'involv', 463: 'iron', 464: 'issu', 465: 'ist', 466: 'iterest', 467: 'java', 468: 'job', 469: 'journey', 470: 'keep', 471: 'kind', 472: 'know', 473: 'knowledg', 474: 'known', 475: 'korea', 476: 'lab', 477: 'labtest', 478: 'lack', 479: 'laid', 480: 'languag', 481: 'larg', 482: 'last', 483: 'late', 484: 'later', 485: 'leaarn', 486: 'lead', 487: 'learn', 488: 'learnt', 489: 'least', 490: 'lectur', 491: 'led', 492: 'lend', 493: 'less', 494: 'lesser', 495: 'lesson', 496: 'let', 497: 'level', 498: 'liais', 499: 'lie', 500: 'life', 501: 'like', 502: 'limit', 503: 'list', 504: 'littl', 505: 'live', 506: 'logger', 507: 'logic', 508: 'long', 509: 'longer', 510: 'look', 511: 'lost', 512: 'lot', 513: 'mac', 514: 'macro', 515: 'made', 516: 'main', 517: 'maintain', 518: 'major', 519: 'make', 520: 'manag', 521: 'mani', 522: 'manner', 523: 'mark', 524: 'mate', 525: 'materi', 526: 'may', 527: 'mayb', 528: 'mean', 529: 'meet', 530: 'meh', 531: 'member', 532: 'mentor', 533: 'mere', 534: 'messi', 535: 'method', 536: 'mid', 537: 'might', 538: 'mileston', 539: 'mind', 540: 'mine', 541: 'minut', 542: 'miss', 543: 'mix', 544: 'mixtur', 545: 'mobil', 546: 'mod', 547: 'model', 548: 'modul', 549: 'monoton', 550: 'morn', 551: 'mostli', 552: 'motiv', 553: 'mous', 554: 'move', 555: 'ms', 556: 'much', 557: 'must', 558: 'mysql', 559: 'name', 560: 'natur', 561: 'nbsp', 562: 'necessari', 563: 'need', 564: 'neg', 565: 'netlogo', 566: 'never', 567: 'nevertheless', 568: 'new', 569: 'next', 570: 'nice', 571: 'night', 572: 'non', 573: 'normal', 574: 'note', 575: 'noth', 576: 'notic', 577: 'npc', 578: 'object', 579: 'offer', 580: 'offic', 581: 'often', 582: 'ok', 583: 'one', 584: 'onto', 585: 'oo', 586: 'ooad', 587: 'open', 588: 'opinion', 589: 'opportun', 590: 'optimis', 591: 'option', 592: 'organ', 593: 'orient', 594: 'outcom', 595: 'outlin', 596: 'outsid', 597: 'overal', 598: 'oversea', 599: 'pace', 600: 'pack', 601: 'page', 602: 'paid', 603: 'panic', 604: 'panjang', 605: 'part', 606: 'parti', 607: 'particip', 608: 'particular', 609: 'pasir', 610: 'pass', 611: 'passion', 612: 'past', 613: 'patienc', 614: 'patient', 615: 'paus', 616: 'pay', 617: 'peopl', 618: 'perform', 619: 'perhap', 620: 'period', 621: 'permiss', 622: 'person', 623: 'perspect', 624: 'pinpoint', 625: 'place', 626: 'plainli', 627: 'platform', 628: 'pleas', 629: 'pleasur', 630: 'point', 631: 'pop', 632: 'portion', 633: 'pose', 634: 'possibl', 635: 'post', 636: 'power', 637: 'practic', 638: 'pragmat', 639: 'pre', 640: 'predict', 641: 'prepar', 642: 'prerequisit', 643: 'present', 644: 'pressur', 645: 'pretti', 646: 'previou', 647: 'principl', 648: 'prior', 649: 'privat', 650: 'pro', 651: 'proactiv', 652: 'probabl', 653: 'problem', 654: 'procedur', 655: 'process', 656: 'produc', 657: 'program', 658: 'progress', 659: 'project', 660: 'pronunci', 661: 'properli', 662: 'propos', 663: 'prospect', 664: 'provid', 665: 'psa', 666: 'public', 667: 'purpos', 668: 'pursu', 669: 'push', 670: 'put', 671: 'quarter', 672: 'queri', 673: 'question', 674: 'quickli', 675: 'quit', 676: 'quizz', 677: 'quri', 678: 'rais', 679: 'random', 680: 'rant', 681: 'rate', 682: 'rather', 683: 'read', 684: 'readi', 685: 'real', 686: 'realis', 687: 'realist', 688: 'realli', 689: 'reason', 690: 'recap', 691: 'receiv', 692: 'recommend', 693: 'recycl', 694: 'redund', 695: 'refer', 696: 'refresh', 697: 'regard', 698: 'regardless', 699: 'relat', 700: 'releas', 701: 'relev', 702: 'reli', 703: 'reliabl', 704: 'remark', 705: 'rememb', 706: 'remov', 707: 'replac', 708: 'report', 709: 'reput', 710: 'requir', 711: 'research', 712: 'resort', 713: 'resourc', 714: 'respect', 715: 'respons', 716: 'rest', 717: 'restrict', 718: 'result', 719: 'review', 720: 'revis', 721: 'rider', 722: 'right', 723: 'risk', 724: 'room', 725: 'rubi', 726: 'rush', 727: 'said', 728: 'sampl', 729: 'sarcast', 730: 'sat', 731: 'saturday', 732: 'say', 733: 'scale', 734: 'scenario', 735: 'school', 736: 'scienc', 737: 'scope', 738: 'scratch', 739: 'second', 740: 'secur', 741: 'see', 742: 'seek', 743: 'seem', 744: 'seemingli', 745: 'segment', 746: 'select', 747: 'self', 748: 'semest', 749: 'sens', 750: 'separ', 751: 'serious', 752: 'session', 753: 'set', 754: 'setup', 755: 'sever', 756: 'share', 757: 'shcedul', 758: 'sheet', 759: 'shift', 760: 'short', 761: 'show', 762: 'shown', 763: 'si', 764: 'similar', 765: 'simpl', 766: 'simpli', 767: 'simplifi', 768: 'simul', 769: 'sinc', 770: 'sincer', 771: 'sit', 772: 'situat', 773: 'skill', 774: 'slide', 775: 'slow', 776: 'slower', 777: 'small', 778: 'smaller', 779: 'smart', 780: 'smu', 781: 'soci', 782: 'social', 783: 'softwar', 784: 'solid', 785: 'solut', 786: 'solv', 787: 'someon', 788: 'someth', 789: 'sometim', 790: 'sorri', 791: 'sort', 792: 'sound', 793: 'sourc', 794: 'span', 795: 'speak', 796: 'speaker', 797: 'specif', 798: 'spend', 799: 'spent', 800: 'split', 801: 'sponsor', 802: 'spreadsheet', 803: 'spur', 804: 'sql', 805: 'stage', 806: 'stakehold', 807: 'standard', 808: 'starri', 809: 'start', 810: 'state', 811: 'statement', 812: 'statist', 813: 'steep', 814: 'step', 815: 'still', 816: 'stimul', 817: 'stock', 818: 'store', 819: 'stori', 820: 'stress', 821: 'strict', 822: 'strictli', 823: 'strongli', 824: 'structur', 825: 'struggl', 826: 'student', 827: 'studi', 828: 'stuff', 829: 'style', 830: 'subject', 831: 'submiss', 832: 'subsidis', 833: 'substanti', 834: 'suffici', 835: 'sugegst', 836: 'suggest', 837: 'summar', 838: 'super', 839: 'supervisor', 840: 'support', 841: 'suppos', 842: 'sure', 843: 'switch', 844: 'sympathi', 845: 'syntax', 846: 'system', 847: 'ta', 848: 'tailor', 849: 'take', 850: 'taken', 851: 'talk', 852: 'taught', 853: 'tax', 854: 'teach', 855: 'team', 856: 'teamwork', 857: 'technic', 858: 'technolog', 859: 'tell', 860: 'templat', 861: 'tend', 862: 'term', 863: 'termin', 864: 'test', 865: 'textbook', 866: 'tgt', 867: 'thank', 868: 'theori', 869: 'there', 870: 'thing', 871: 'think', 872: 'thorough', 873: 'thoroughli', 874: 'though', 875: 'thought', 876: 'throughout', 877: 'throw', 878: 'thu', 879: 'tibco', 880: 'tight', 881: 'time', 882: 'timelin', 883: 'tip', 884: 'tire', 885: 'togeth', 886: 'toler', 887: 'tone', 888: 'tongu', 889: 'took', 890: 'tool', 891: 'topic', 892: 'total', 893: 'touch', 894: 'tough', 895: 'toward', 896: 'transient', 897: 'trend', 898: 'tri', 899: 'trip', 900: 'trivial', 901: 'true', 902: 'tutor', 903: 'tutori', 904: 'tweak', 905: 'two', 906: 'type', 907: 'ultim', 908: 'unabl', 909: 'unclear', 910: 'understand', 911: 'understood', 912: 'unfair', 913: 'unfairli', 914: 'unfamiliar', 915: 'unfocus', 916: 'unforeseen', 917: 'ungrad', 918: 'uninspir', 919: 'univers', 920: 'unless', 921: 'unlik', 922: 'unneed', 923: 'unprepar', 924: 'unrel', 925: 'unstructur', 926: 'unsur', 927: 'unwant', 928: 'upbeat', 929: 'us', 930: 'usag', 931: 'use', 932: 'useless', 933: 'user', 934: 'util', 935: 'v', 936: 'vagu', 937: 'valid', 938: 'valu', 939: 'valuabl', 940: 'variou', 941: 'vba', 942: 'view', 943: 'visit', 944: 'vm', 945: 'vs', 946: 'want', 947: 'way', 948: 'weaker', 949: 'web', 950: 'week', 951: 'weekend', 952: 'weekli', 953: 'well', 954: 'went', 955: 'what', 956: 'whatev', 957: 'whenev', 958: 'whether', 959: 'whole', 960: 'wholeheartedli', 961: 'whyyi', 962: 'wide', 963: 'will', 964: 'wind', 965: 'wise', 966: 'within', 967: 'without', 968: 'work', 969: 'workflow', 970: 'workforc', 971: 'workload', 972: 'workplac', 973: 'world', 974: 'worst', 975: 'would', 976: 'write', 977: 'wrong', 978: 'xml', 979: 'xxxx', 980: 'xxxxxxxx', 981: 'year'}\n"
     ]
    }
   ],
   "source": [
    "token_to_id = dictionary.token2id\n",
    "token_to_id_swap = {value:key for key, value in token_to_id.items()}\n",
    "print(token_to_id_swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"Do you have a doctor's note recommending you to WFH? My colleague has it.\"\n",
    "comment = word_tokenize(comment)\n",
    "\n",
    "cmt_lower = [w.lower() for w in comment]\n",
    "cmt_alpha = [w for w in cmt_lower if re.search('^[a-z]+$', w)]\n",
    "\n",
    "stop_list = stopwords.words('english')\n",
    "cmt_stop = [w for w in cmt_alpha if w not in stop_list]\n",
    "\n",
    "# Perform Porter stemming. Store in variable docs_stem\n",
    "stemmer = PorterStemmer()\n",
    "cmt_stem = [stemmer.stem(w) for w in cmt_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = dictionary.doc2bow(cmt_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(574, 1), (692, 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "row = []"
   ]
  },
  {
   "source": [
    "# Getting actionable comments with actionable keywords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Twitter Data/Cleaned Data/Policies/Safe entry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "len(twitter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "actionable_keywords = set(['should', 'may be', 'maybe', 'to be', 'need to', 'believe', 'suppose to', 'ought', 'hope', 'have to', 'suggest', 'must', 'advise', 'request', 'needs to', 'require', 'better', 'why cant', 'how about', 'expect', 'please', 'why not'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n"
     ]
    }
   ],
   "source": [
    "actionable_comment = pd.DataFrame(columns = twitter_df.columns)\n",
    "\n",
    "for i, row in twitter_df.iterrows():\n",
    "    comment_words = set(str(row['tweet']).split())\n",
    "    if len(actionable_keywords.intersection(comment_words)) > 0:\n",
    "        print(True)\n",
    "        actionable_comment = actionable_comment.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "len(actionable_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13    And I hope the #SafeEntry Admins are counting ...\n",
       "20    Omg just went to eat in Tekka Market, took one...\n",
       "44    Someone better remind Santa about the face mas...\n",
       "46    @ericrazali Zucc enters a restaurant with his ...\n",
       "50    @AaronAtayde Wala pa ding safe entry scan bar ...\n",
       "75    I mean the SafeEntry app, should have 4 languages\n",
       "76    SafeEntry should support 4 languages for the s...\n",
       "81    #庆祝美业开工啦 Welcome Back Reopening 19/6🥳🥳🥳 Lookin...\n",
       "97    I used SafeEntry today and it was seamless exp...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "actionable_comment['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Collating comments for thoughtful comments labelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_entry = []\n",
    "Tracetogether = []\n",
    "vaccination = []\n",
    "circuit_breaker = []\n",
    "\n",
    "comments = pd.DataFrame(columns=[\"topic\", \"comment\"])"
   ]
  },
  {
   "source": [
    "### Vaccination"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "df1 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Instagram Data/Cleaned Data/Manual Scrape/Mothership/Vaccination.csv\")\n",
    "df2 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Instagram Data/Cleaned Data/Manual Scrape/Straits Times/Vaccination.csv\")\n",
    "df3 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Reddit Data/Cleaned Data/Policies/vaccination.csv\")\n",
    "df4 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Twitter Data/Cleaned Data/Policies/Vaccination.csv\")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = df1['comment']\n",
    "s2 = df2['comment']\n",
    "s3 = df3['comment_body']\n",
    "s4 = df4['tweet']\n",
    "\n",
    "vaccination = pd.concat([s1, s2, s3, s4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccination_sample = pd.DataFrame({\"comment\": vaccination.sample(n = 500)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               comment\n",
       "0    Herd immunity kicks in at around 70% so we don...\n",
       "1    straight up get struck by lightning better.\\n\\...\n",
       "2    The guide to getting the COVID-19 vaccine out ...\n",
       "3             Other countries sud learn from Singapore\n",
       "4    Catholic priest developing COVID-19 vaccine fo...\n",
       "..                                                 ...\n",
       "495  Racist Trump. You claim that the vaccine will ...\n",
       "496  Facebook and Instagram will ban accounts sprea...\n",
       "497  maybe it’s just in my head but i’m awfully tir...\n",
       "498  CoVid Vaccine is coming 😲  https://t.co/84dRpN...\n",
       "499            i hope the vaccine would be a success:D\n",
       "\n",
       "[500 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Herd immunity kicks in at around 70% so we don...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>straight up get struck by lightning better.\\n\\...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The guide to getting the COVID-19 vaccine out ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Other countries sud learn from Singapore</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Catholic priest developing COVID-19 vaccine fo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>Racist Trump. You claim that the vaccine will ...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>Facebook and Instagram will ban accounts sprea...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>maybe it’s just in my head but i’m awfully tir...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>CoVid Vaccine is coming 😲  https://t.co/84dRpN...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>i hope the vaccine would be a success:D</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "vaccination_sample = vaccination_sample.reset_index()\n",
    "vaccination_sample.drop('index', axis = 1, inplace=True)\n",
    "vaccination_sample.to_excel(\"/Users/chenjianyu/Desktop/vaccination.xls\")"
   ]
  },
  {
   "source": [
    "### Tracetogether"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Instagram Data/Cleaned Data/Manual Scrape/Mothership/TraceTogether.csv\")\n",
    "df2 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Instagram Data/Cleaned Data/Manual Scrape/Straits Times/TraceTogether.csv\")\n",
    "df3 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Reddit Data/Cleaned Data/Policies/Tracetogether.csv\")\n",
    "df4 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Twitter Data/Cleaned Data/Policies/Tracetogether.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = df1['comment']\n",
    "s2 = df2['comment']\n",
    "s3 = df3['comment_body']\n",
    "s4 = df4['tweet']\n",
    "\n",
    "tracetogether = pd.concat([s1, s2, s3, s4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracetogether_sample = pd.DataFrame({\"comment\": tracetogether.sample(n = 500)})\n",
    "tracetogether_sample = tracetogether_sample.reset_index()\n",
    "tracetogether_sample.drop('index', axis = 1, inplace=True)\n",
    "tracetogether_sample.to_excel(\"/Users/chenjianyu/Desktop/Tracetogether.xls\")"
   ]
  },
  {
   "source": [
    "### Safe distancing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Reddit Data/Cleaned Data/Policies/social_distancing.csv\")\n",
    "df2 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Twitter Data/Cleaned Data/Policies/Safe distancing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = df1['comment_body']\n",
    "s2 = df2['tweet']\n",
    "\n",
    "safe_distancing = pd.concat([s1, s2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_distancing_sample = pd.DataFrame({\"comment\": safe_distancing.sample(n = 500)})\n",
    "safe_distancing_sample = safe_distancing_sample.reset_index()\n",
    "safe_distancing_sample.drop('index', axis = 1, inplace=True)\n",
    "safe_distancing_sample.to_excel(\"/Users/chenjianyu/Desktop/safe_distancing.xls\")"
   ]
  },
  {
   "source": [
    "### Circuit breaker"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Reddit Data/Cleaned Data/Policies/circuit_breaker.csv\")\n",
    "df2 = pd.read_csv(\"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Twitter Data/Cleaned Data/Policies/Circuit breaker.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = df1['comment_body']\n",
    "s2 = df2['tweet']\n",
    "\n",
    "cb = pd.concat([s1, s2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_sample = pd.DataFrame({\"comment\": cb.sample(n = 500)})\n",
    "cb_sample = cb_sample.reset_index()\n",
    "cb_sample.drop('index', axis = 1, inplace=True)\n",
    "cb_sample.to_excel(\"/Users/chenjianyu/Desktop/circuit_breaker.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Tweet tokenizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"@Luna11053 ちょっとまだ半年ほど日本でのmass vaccinationまでにはタイムラグがあるので、それまでの間に分科会なり自治体なりで接種方法は戦略組まないといけないなぁと思います。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['@Luna11053',\n",
       " 'ちょっとまだ半年ほど日本でのmass',\n",
       " 'vaccinationまでにはタイムラグがあるので',\n",
       " '、',\n",
       " 'それまでの間に分科会なり自治体なりで接種方法は戦略組まないといけないなぁと思います',\n",
       " '。']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "tweet_tokenizer.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Reddit stay_home1_comments.csv',\n",
       " 'Reddit stay_home1_posts.csv',\n",
       " 'Reddit stay_home_notice_comments.csv',\n",
       " 'Reddit stay_home_notice_posts.csv']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "path = '/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Reddit Data/Raw Data/Policies/Stay home notice'\n",
    "\n",
    "files = [filename for filename in os.listdir(path) if filename.endswith('.csv')]\n",
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Facebook Data/Raw Data (with timestamp)/fbposts_moh_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "posts = df['text']\n",
    "daily_updates = []\n",
    "non_updates = []\n",
    "for post in posts:\n",
    "    if type(post) == str and post[:6] == \"As of \":\n",
    "        daily_updates.append(post)\n",
    "    else:\n",
    "        non_updates.append(post)\n",
    "\n",
    "daily_updates_df = pd.DataFrame({'posts':daily_updates})\n",
    "non_updates_df = pd.DataFrame({'posts':non_updates})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1410\n716\n694\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(daily_updates_df))\n",
    "print(len(non_updates_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1410"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Thoughtful Comments/thoughtful_comments_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = df['Comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "actionable_words = \"should, shd, shld, may be, may b, maybe, mayb, to be, needs to, nids to, need to, nid to, believe, suppose to, ought, hope, have to, hav to, hv to, suggest, must, advise, request, require, better, btr, why cannot, why cant, why cnt, how about, how bout, expect, please, pls, plz, why not, y not\"\n",
    "actionable_words = actionable_words.split(', ')\n",
    "for i, w in enumerate(actionable_words):\n",
    "    actionable_words[i] = ' ' + w + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " ever be a vaccine. Even the reg flu vaccine is no guarantee. We need to focus and move forward.\n\n have to \n@melissakchan @profgalloway My guess is we have to live with it and there won't be ever be a vaccine. Even the reg flu vaccine is no guarantee. We need to focus and move forward.\n\n to be \nAfter conducting a press conference every day for almost a year Malaysia’s Director General of Health @DGHisham is now calling on the media to be a vaccine against fake news. https://t.co/iNlN3qEHJ6 https://t.co/mFjbxxzic5\n\n to be \nBREAKING: Singapore to enter #phase3 on 28 Dec, group gatherings limit raised from 5 to 8. Vaccines to be made free for all Singaporeans when available, but will be on voluntary basis.\n\n must \n@SAfmRadio @StephenGrootes For wht purpose exactly? Why must we use/spend money on vaccine tht is not affective to the variant we hv in SA, when other countries are using vaccine tht are 90% more affective?\n\n to be \nThey will in all likelihood roll out the vaccination plans based on a combination of risk profiles (elderly, frail/immune-suppressed individuals, healthcare workers etc.) and economically vital professions (Airport staff, construction etc.).\n\nMost healthy adults will probably be the last to be eligible for the vaccination\n\n to be \n@QueenOfMyHappi1 @baymath So heres a thought. If the only vaccines available were not as effective on the variant that most dominant here, and the JnJ was not found to be more effective would we rather say let's not have any? No. We also have to retest efficacy when things arrive on our own. A catch 22\n\n have to \n@QueenOfMyHappi1 @baymath So heres a thought. If the only vaccines available were not as effective on the variant that most dominant here, and the JnJ was not found to be more effective would we rather say let's not have any? No. We also have to retest efficacy when things arrive on our own. A catch 22\n\n should \nWhat am I twisting? You say there’s no data. Which is correct, there isn’t. A doctor says because there is no data, we don’t know the long term risks. So maybe don’t take immediately, wait and see. And yet somehow the doctor who says this is wrong in your world view because he should keep that opinion to himself? \n\nI mean all your responses have been saying that doctors shouldn’t be saying anything contrary about the vaccine even though they should be doing risk assessments. Risk assessment isn’t just about the immediacy of COVID, it’s also about the future. As an example, doing knee replacement. It improves quality of life now but it has to be replaced. That’s why doctors have to explain the risks to their older patients because if they outlive the replacement, they then have to be on wheelchair or undergo another surgery which is highly risky at an even older age. \n\nAnd couple that with the fact that Singapore has very low number of community cases now. Why is there surprise people are a lot more cautious about putting something into their bodies?\n\n maybe \nWhat am I twisting? You say there’s no data. Which is correct, there isn’t. A doctor says because there is no data, we don’t know the long term risks. So maybe don’t take immediately, wait and see. And yet somehow the doctor who says this is wrong in your world view because he should keep that opinion to himself? \n\nI mean all your responses have been saying that doctors shouldn’t be saying anything contrary about the vaccine even though they should be doing risk assessments. Risk assessment isn’t just about the immediacy of COVID, it’s also about the future. As an example, doing knee replacement. It improves quality of life now but it has to be replaced. That’s why doctors have to explain the risks to their older patients because if they outlive the replacement, they then have to be on wheelchair or undergo another surgery which is highly risky at an even older age. \n\nAnd couple that with the fact that Singapore has very low number of community cases now. Why is there surprise people are a lot more cautious about putting something into their bodies?\n\n to be \nWhat am I twisting? You say there’s no data. Which is correct, there isn’t. A doctor says because there is no data, we don’t know the long term risks. So maybe don’t take immediately, wait and see. And yet somehow the doctor who says this is wrong in your world view because he should keep that opinion to himself? \n\nI mean all your responses have been saying that doctors shouldn’t be saying anything contrary about the vaccine even though they should be doing risk assessments. Risk assessment isn’t just about the immediacy of COVID, it’s also about the future. As an example, doing knee replacement. It improves quality of life now but it has to be replaced. That’s why doctors have to explain the risks to their older patients because if they outlive the replacement, they then have to be on wheelchair or undergo another surgery which is highly risky at an even older age. \n\nAnd couple that with the fact that Singapore has very low number of community cases now. Why is there surprise people are a lot more cautious about putting something into their bodies?\n\n have to \nWhat am I twisting? You say there’s no data. Which is correct, there isn’t. A doctor says because there is no data, we don’t know the long term risks. So maybe don’t take immediately, wait and see. And yet somehow the doctor who says this is wrong in your world view because he should keep that opinion to himself? \n\nI mean all your responses have been saying that doctors shouldn’t be saying anything contrary about the vaccine even though they should be doing risk assessments. Risk assessment isn’t just about the immediacy of COVID, it’s also about the future. As an example, doing knee replacement. It improves quality of life now but it has to be replaced. That’s why doctors have to explain the risks to their older patients because if they outlive the replacement, they then have to be on wheelchair or undergo another surgery which is highly risky at an even older age. \n\nAnd couple that with the fact that Singapore has very low number of community cases now. Why is there surprise people are a lot more cautious about putting something into their bodies?\n\n need to \nExactly. This is what I hope the goverment has the balls to do. Fuck public sentiment. Sometimes you need to grab someone by their tits and tell them what's good for them\n\n hope \nExactly. This is what I hope the goverment has the balls to do. Fuck public sentiment. Sometimes you need to grab someone by their tits and tell them what's good for them\n\n should \nIs this actually the reason Australia are waiting until March? I'm deeply sceptical of this because 3 months is almost nothing considering that these vaccines have been in trials for longer than that. To hesitate is not necessarily a reasonable response. The proportion of people that are going to have long-term health effects from covid (even young and healthy people) is going to be far greater than from the approved vaccine. So anyone seriously worried about side effects should probably be staying at home at all times to prevent themselves getting covid.\n\n to be \nIs this actually the reason Australia are waiting until March? I'm deeply sceptical of this because 3 months is almost nothing considering that these vaccines have been in trials for longer than that. To hesitate is not necessarily a reasonable response. The proportion of people that are going to have long-term health effects from covid (even young and healthy people) is going to be far greater than from the approved vaccine. So anyone seriously worried about side effects should probably be staying at home at all times to prevent themselves getting covid.\n\n to be \nLong term side effects usually comes from long term use of a medication. It happens because the way modern medicine works. \n\nThe body has lots of natural processes going on. Some of this processes, when out of “balance”, can lead to disease. Drugs target aspects of such biological processes to bring it back to “balance”, sometimes by blocking it, sometimes by enhancing it. \n\nDrugs are *small* molecules. The body doesn’t care about the atoms making up the molecule, the body cares about the *shape*. These specially designed drug molecules go into the protein (or other molecules) and do its “magic”, affecting the natural biological processes and bring it into balance.\n\nOne problem with this is that the body sometimes likes to reuse the same protein (or family of similar proteins) in different places to control different processes. A drug may unintentionally affect an otherwise unintended process(es) and cause long term unforseen problems.\n\nAnother problem is that a drug can target some completely unexpected target. As I said earlier, the shape is important. While a drug can be designed to fit a certain protein, there is chance that by coincidence, it can also hit some unrelated protein elsewhere and affect other processes and cause problems in the long term.\n\nAlso, ultimately, all drugs are poison and the only thing that differentiate medicine from poison is the dosage. Too much of an effect can be bad. There are drugs that can cause damage to organs at higher dosages, for example. \n\nSometimes, the drug molecule itself can be chemically reactive, and can cause damage. Keep using it and you get long term damage. Rarely, if such chemically reactive drug damage the DNA enough over the years, people can even get cancer. Fortunately, people know some of the common reactive features and avoid those.\n\nTo complicate things, the body tends to do things to a drug molecule to make it easier to get rid of it. That thing can be inherently toxic (such as one of paracetamol/panadol’s metabolite), or it can have effects of its own.\n\nThere are a lot of ways for a drug to cause long term problems and side effects. However, does this mean mRNA vaccines can do so too? There are differences between mRNA and drug molecules and that makes things different.\n\nUltimately, mRNA is a naturally occuring information carrying molecule. You have it in your body and it comes in many different lengths. The mRNA in the vaccine is not going to be any more reactive than those you already have!\n\nCompared to drug molecules, mRNA are huge. Things bind to sites on the mRNA, not really the other way around. It’s not very likely to trigger things you wouldn’t expect a normal mRNA to trigger.\n\nInherently, mRNA are not toxic, so that is one safe part.\n\nAlthough we cannot rule out the possibility that the viral product it encode for can target unwanted processes and cause effects, it isn’t something very likely. Given that mRNA is not very stable, it doesn’t stay for long and you are only exposed to the amounts injected. Even if the product is not harmless, it is transient and shouldn’t cause too much of an effect, and unlikely to cause a long-term one. Your body can take a bit of damage. You go out under the sun? Damage. Eat or touch stuff too hot? Damage. Etc etc.\n\nIt would be *far worse* to get the real deal, since the actual virus can replicate and make much much more potentially harmful viral proteins that a mRNA vaccine can cause your body to produce, on top of other problems associated with the actual covid virus.\n\nTo be honest, the most likely reactions are immune related ones and those most side effects are short term and not likely to be very harmful.\n\nIf you react very negatively to the mRNA in the vaccine and the protein it produces, I don’t think you would fare any better with the real virus.\n\nThe chances of the vaccine working as intended safely is high, probably better odds with that then the odds between mild and serious covid.\n\n better \nLong term side effects usually comes from long term use of a medication. It happens because the way modern medicine works. \n\nThe body has lots of natural processes going on. Some of this processes, when out of “balance”, can lead to disease. Drugs target aspects of such biological processes to bring it back to “balance”, sometimes by blocking it, sometimes by enhancing it. \n\nDrugs are *small* molecules. The body doesn’t care about the atoms making up the molecule, the body cares about the *shape*. These specially designed drug molecules go into the protein (or other molecules) and do its “magic”, affecting the natural biological processes and bring it into balance.\n\nOne problem with this is that the body sometimes likes to reuse the same protein (or family of similar proteins) in different places to control different processes. A drug may unintentionally affect an otherwise unintended process(es) and cause long term unforseen problems.\n\nAnother problem is that a drug can target some completely unexpected target. As I said earlier, the shape is important. While a drug can be designed to fit a certain protein, there is chance that by coincidence, it can also hit some unrelated protein elsewhere and affect other processes and cause problems in the long term.\n\nAlso, ultimately, all drugs are poison and the only thing that differentiate medicine from poison is the dosage. Too much of an effect can be bad. There are drugs that can cause damage to organs at higher dosages, for example. \n\nSometimes, the drug molecule itself can be chemically reactive, and can cause damage. Keep using it and you get long term damage. Rarely, if such chemically reactive drug damage the DNA enough over the years, people can even get cancer. Fortunately, people know some of the common reactive features and avoid those.\n\nTo complicate things, the body tends to do things to a drug molecule to make it easier to get rid of it. That thing can be inherently toxic (such as one of paracetamol/panadol’s metabolite), or it can have effects of its own.\n\nThere are a lot of ways for a drug to cause long term problems and side effects. However, does this mean mRNA vaccines can do so too? There are differences between mRNA and drug molecules and that makes things different.\n\nUltimately, mRNA is a naturally occuring information carrying molecule. You have it in your body and it comes in many different lengths. The mRNA in the vaccine is not going to be any more reactive than those you already have!\n\nCompared to drug molecules, mRNA are huge. Things bind to sites on the mRNA, not really the other way around. It’s not very likely to trigger things you wouldn’t expect a normal mRNA to trigger.\n\nInherently, mRNA are not toxic, so that is one safe part.\n\nAlthough we cannot rule out the possibility that the viral product it encode for can target unwanted processes and cause effects, it isn’t something very likely. Given that mRNA is not very stable, it doesn’t stay for long and you are only exposed to the amounts injected. Even if the product is not harmless, it is transient and shouldn’t cause too much of an effect, and unlikely to cause a long-term one. Your body can take a bit of damage. You go out under the sun? Damage. Eat or touch stuff too hot? Damage. Etc etc.\n\nIt would be *far worse* to get the real deal, since the actual virus can replicate and make much much more potentially harmful viral proteins that a mRNA vaccine can cause your body to produce, on top of other problems associated with the actual covid virus.\n\nTo be honest, the most likely reactions are immune related ones and those most side effects are short term and not likely to be very harmful.\n\nIf you react very negatively to the mRNA in the vaccine and the protein it produces, I don’t think you would fare any better with the real virus.\n\nThe chances of the vaccine working as intended safely is high, probably better odds with that then the odds between mild and serious covid.\n\n expect \nLong term side effects usually comes from long term use of a medication. It happens because the way modern medicine works. \n\nThe body has lots of natural processes going on. Some of this processes, when out of “balance”, can lead to disease. Drugs target aspects of such biological processes to bring it back to “balance”, sometimes by blocking it, sometimes by enhancing it. \n\nDrugs are *small* molecules. The body doesn’t care about the atoms making up the molecule, the body cares about the *shape*. These specially designed drug molecules go into the protein (or other molecules) and do its “magic”, affecting the natural biological processes and bring it into balance.\n\nOne problem with this is that the body sometimes likes to reuse the same protein (or family of similar proteins) in different places to control different processes. A drug may unintentionally affect an otherwise unintended process(es) and cause long term unforseen problems.\n\nAnother problem is that a drug can target some completely unexpected target. As I said earlier, the shape is important. While a drug can be designed to fit a certain protein, there is chance that by coincidence, it can also hit some unrelated protein elsewhere and affect other processes and cause problems in the long term.\n\nAlso, ultimately, all drugs are poison and the only thing that differentiate medicine from poison is the dosage. Too much of an effect can be bad. There are drugs that can cause damage to organs at higher dosages, for example. \n\nSometimes, the drug molecule itself can be chemically reactive, and can cause damage. Keep using it and you get long term damage. Rarely, if such chemically reactive drug damage the DNA enough over the years, people can even get cancer. Fortunately, people know some of the common reactive features and avoid those.\n\nTo complicate things, the body tends to do things to a drug molecule to make it easier to get rid of it. That thing can be inherently toxic (such as one of paracetamol/panadol’s metabolite), or it can have effects of its own.\n\nThere are a lot of ways for a drug to cause long term problems and side effects. However, does this mean mRNA vaccines can do so too? There are differences between mRNA and drug molecules and that makes things different.\n\nUltimately, mRNA is a naturally occuring information carrying molecule. You have it in your body and it comes in many different lengths. The mRNA in the vaccine is not going to be any more reactive than those you already have!\n\nCompared to drug molecules, mRNA are huge. Things bind to sites on the mRNA, not really the other way around. It’s not very likely to trigger things you wouldn’t expect a normal mRNA to trigger.\n\nInherently, mRNA are not toxic, so that is one safe part.\n\nAlthough we cannot rule out the possibility that the viral product it encode for can target unwanted processes and cause effects, it isn’t something very likely. Given that mRNA is not very stable, it doesn’t stay for long and you are only exposed to the amounts injected. Even if the product is not harmless, it is transient and shouldn’t cause too much of an effect, and unlikely to cause a long-term one. Your body can take a bit of damage. You go out under the sun? Damage. Eat or touch stuff too hot? Damage. Etc etc.\n\nIt would be *far worse* to get the real deal, since the actual virus can replicate and make much much more potentially harmful viral proteins that a mRNA vaccine can cause your body to produce, on top of other problems associated with the actual covid virus.\n\nTo be honest, the most likely reactions are immune related ones and those most side effects are short term and not likely to be very harmful.\n\nIf you react very negatively to the mRNA in the vaccine and the protein it produces, I don’t think you would fare any better with the real virus.\n\nThe chances of the vaccine working as intended safely is high, probably better odds with that then the odds between mild and serious covid.\n\n should \nhttps://www.reddit.com/r/singapore/comments/kt202y/singapores_3_covid19_vaccines_and_is_one_better/gimwvlf/?utm_source=share&utm_medium=ios_app&utm_name=iossmf&context=3\n\nDid a sus on sinovac in another thread and received a gold reply on how we should still have some faith on the vaccine approving process.\n\n hope \ni hope the vaccine would be a success:D\n\n"
     ]
    }
   ],
   "source": [
    "actionable_comments = []\n",
    "for comment in comments:\n",
    "    for w in actionable_words:\n",
    "        if w in comment:\n",
    "            actionable_comments.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "447"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "len(actionable_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "actionable_comments = pd.DataFrame({'comment':actionable_comments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "actionable_comments.to_csv('/Users/chenjianyu/Desktop/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Features EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Thoughtful Comments/thoughtful_comments_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                            Comment  Label1  \\\n",
       "0           0  🇸🇬New Parc Clematis National Day Promo startin...       0   \n",
       "1           1  Oh my fucking God, this announcement could not...       0   \n",
       "2           2  Dang it. I was super happy for a while.\\n\\nIt'...       0   \n",
       "3           3  After a beautiful front 9 we got hit with the ...       0   \n",
       "4           4  these people must be tagged, if not cannot ent...       0   \n",
       "\n",
       "   Label2  Label3  Thoughtful?            Topic  Length  \\\n",
       "0       0       0            0  circuit breaker      34   \n",
       "1       0       0            0  circuit breaker      94   \n",
       "2       0       0            0  circuit breaker      18   \n",
       "3       0       0            0  circuit breaker      11   \n",
       "4       0       0            0  circuit breaker      11   \n",
       "\n",
       "   Average Loglikelihood  Num Verbs  Num Discourse Relations  Relevance score  \n",
       "0             -13.944796          4                        0         5.691875  \n",
       "1             -11.286315         16                        2         3.849035  \n",
       "2              -9.626479          3                        0        36.848291  \n",
       "3             -13.549426          2                        0        26.305341  \n",
       "4             -11.213937          2                        1        55.383696  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Comment</th>\n      <th>Label1</th>\n      <th>Label2</th>\n      <th>Label3</th>\n      <th>Thoughtful?</th>\n      <th>Topic</th>\n      <th>Length</th>\n      <th>Average Loglikelihood</th>\n      <th>Num Verbs</th>\n      <th>Num Discourse Relations</th>\n      <th>Relevance score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>🇸🇬New Parc Clematis National Day Promo startin...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>circuit breaker</td>\n      <td>34</td>\n      <td>-13.944796</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5.691875</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Oh my fucking God, this announcement could not...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>circuit breaker</td>\n      <td>94</td>\n      <td>-11.286315</td>\n      <td>16</td>\n      <td>2</td>\n      <td>3.849035</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Dang it. I was super happy for a while.\\n\\nIt'...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>circuit breaker</td>\n      <td>18</td>\n      <td>-9.626479</td>\n      <td>3</td>\n      <td>0</td>\n      <td>36.848291</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>After a beautiful front 9 we got hit with the ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>circuit breaker</td>\n      <td>11</td>\n      <td>-13.549426</td>\n      <td>2</td>\n      <td>0</td>\n      <td>26.305341</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>these people must be tagged, if not cannot ent...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>circuit breaker</td>\n      <td>11</td>\n      <td>-11.213937</td>\n      <td>2</td>\n      <td>1</td>\n      <td>55.383696</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Unnamed: 0       Label1       Label2       Label3  Thoughtful?  \\\n",
       "count  1962.000000  1962.000000  1962.000000  1962.000000  1962.000000   \n",
       "mean    980.500000     0.077982     0.145770     0.135066     0.104485   \n",
       "std     566.524933     0.268211     0.352965     0.341881     0.305967   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%     490.250000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%     980.500000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    1470.750000     0.000000     0.000000     0.000000     0.000000   \n",
       "max    1961.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            Length  Average Loglikelihood    Num Verbs  \\\n",
       "count  1962.000000            1962.000000  1962.000000   \n",
       "mean     29.736493             -12.723922     5.483690   \n",
       "std      44.441453               2.445629     8.927436   \n",
       "min       1.000000             -23.139567     0.000000   \n",
       "25%      10.000000             -13.940537     1.000000   \n",
       "50%      20.000000             -12.112523     3.000000   \n",
       "75%      35.000000             -10.988970     7.000000   \n",
       "max     888.000000              -7.103919   191.000000   \n",
       "\n",
       "       Num Discourse Relations  Relevance score  \n",
       "count              1962.000000      1962.000000  \n",
       "mean                  1.117227        19.293761  \n",
       "std                   2.097695        43.160822  \n",
       "min                   0.000000        -0.143343  \n",
       "25%                   0.000000         3.957418  \n",
       "50%                   1.000000         7.684996  \n",
       "75%                   1.750000        16.539838  \n",
       "max                  41.000000       408.447008  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Label1</th>\n      <th>Label2</th>\n      <th>Label3</th>\n      <th>Thoughtful?</th>\n      <th>Length</th>\n      <th>Average Loglikelihood</th>\n      <th>Num Verbs</th>\n      <th>Num Discourse Relations</th>\n      <th>Relevance score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1962.000000</td>\n      <td>1962.000000</td>\n      <td>1962.000000</td>\n      <td>1962.000000</td>\n      <td>1962.000000</td>\n      <td>1962.000000</td>\n      <td>1962.000000</td>\n      <td>1962.000000</td>\n      <td>1962.000000</td>\n      <td>1962.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>980.500000</td>\n      <td>0.077982</td>\n      <td>0.145770</td>\n      <td>0.135066</td>\n      <td>0.104485</td>\n      <td>29.736493</td>\n      <td>-12.723922</td>\n      <td>5.483690</td>\n      <td>1.117227</td>\n      <td>19.293761</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>566.524933</td>\n      <td>0.268211</td>\n      <td>0.352965</td>\n      <td>0.341881</td>\n      <td>0.305967</td>\n      <td>44.441453</td>\n      <td>2.445629</td>\n      <td>8.927436</td>\n      <td>2.097695</td>\n      <td>43.160822</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>-23.139567</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.143343</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>490.250000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10.000000</td>\n      <td>-13.940537</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>3.957418</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>980.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>20.000000</td>\n      <td>-12.112523</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>7.684996</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1470.750000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>35.000000</td>\n      <td>-10.988970</td>\n      <td>7.000000</td>\n      <td>1.750000</td>\n      <td>16.539838</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1961.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>888.000000</td>\n      <td>-7.103919</td>\n      <td>191.000000</td>\n      <td>41.000000</td>\n      <td>408.447008</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_category = []\n",
    "for length in df['Length']:\n",
    "    if length <= 10:\n",
    "        length_category.append(0)\n",
    "    elif 11 <= length <= 25:\n",
    "        length_category.append(1)\n",
    "    elif 26 <= length <= 50:\n",
    "        length_category.append(2)\n",
    "    elif 51 <= length <= 100:\n",
    "        length_category.append(3)\n",
    "    else:\n",
    "        length_category.append(4)\n",
    "df['Length Category'] = length_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                            Comment  Label1  \\\n",
       "0           0  🇸🇬New Parc Clematis National Day Promo startin...       0   \n",
       "1           1  Oh my fucking God, this announcement could not...       0   \n",
       "2           2  Dang it. I was super happy for a while.\\n\\nIt'...       0   \n",
       "3           3  After a beautiful front 9 we got hit with the ...       0   \n",
       "4           4  these people must be tagged, if not cannot ent...       0   \n",
       "\n",
       "   Label2  Label3  Thoughtful?            Topic  Length  \\\n",
       "0       0       0            0  circuit breaker      34   \n",
       "1       0       0            0  circuit breaker      94   \n",
       "2       0       0            0  circuit breaker      18   \n",
       "3       0       0            0  circuit breaker      11   \n",
       "4       0       0            0  circuit breaker      11   \n",
       "\n",
       "   Average Loglikelihood  Num Verbs  Num Discourse Relations  Relevance score  \\\n",
       "0             -13.944796          4                        0         5.691875   \n",
       "1             -11.286315         16                        2         3.849035   \n",
       "2              -9.626479          3                        0        36.848291   \n",
       "3             -13.549426          2                        0        26.305341   \n",
       "4             -11.213937          2                        1        55.383696   \n",
       "\n",
       "   Length Category  \n",
       "0                2  \n",
       "1                3  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Comment</th>\n      <th>Label1</th>\n      <th>Label2</th>\n      <th>Label3</th>\n      <th>Thoughtful?</th>\n      <th>Topic</th>\n      <th>Length</th>\n      <th>Average Loglikelihood</th>\n      <th>Num Verbs</th>\n      <th>Num Discourse Relations</th>\n      <th>Relevance score</th>\n      <th>Length Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>🇸🇬New Parc Clematis National Day Promo startin...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>circuit breaker</td>\n      <td>34</td>\n      <td>-13.944796</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5.691875</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Oh my fucking God, this announcement could not...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>circuit breaker</td>\n      <td>94</td>\n      <td>-11.286315</td>\n      <td>16</td>\n      <td>2</td>\n      <td>3.849035</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Dang it. I was super happy for a while.\\n\\nIt'...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>circuit breaker</td>\n      <td>18</td>\n      <td>-9.626479</td>\n      <td>3</td>\n      <td>0</td>\n      <td>36.848291</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>After a beautiful front 9 we got hit with the ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>circuit breaker</td>\n      <td>11</td>\n      <td>-13.549426</td>\n      <td>2</td>\n      <td>0</td>\n      <td>26.305341</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>these people must be tagged, if not cannot ent...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>circuit breaker</td>\n      <td>11</td>\n      <td>-11.213937</td>\n      <td>2</td>\n      <td>1</td>\n      <td>55.383696</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './Data/Hardwarezone Data/Raw Data/New/hwz_vaccination_posts.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['post datetime'] = pd.to_datetime(df['datetime'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "path = \"/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Facebook Data/Cleaned Data/Policies\"\n",
    "folders = [folder for folder in os.listdir(path) if folder != '.DS_Store' and folder != 'Combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    files = [file for file in os.listdir(f'{path}/{folder}') if file != '.DS_Store']\n",
    "\n",
    "    frames = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(f'{path}/{folder}/{file}')\n",
    "        frames.append(df)\n",
    "    combined = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    filename = folder + '_combined.csv'\n",
    "    combined.to_csv(f'{path}/{folder}/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "df = pd.read_csv('/Users/chenjianyu/Desktop/Y2S2/SMT203 Computational Social Sci/Covid-19-Singapore-Analysis/Data/Facebook Data/Raw Data (with timestamp)/Gov.sg/vaccination_govsg.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for row in df['date_time']:\n",
    "    if '2020' not in row:\n",
    "        row += ' 2021'\n",
    "    if 'at' in row:\n",
    "        try:\n",
    "            date_time = dt.datetime.strptime(row, '%b %d at %I:%M %p %Y')\n",
    "        except:\n",
    "            pass\n",
    "    elif '-' in row:\n",
    "        date_time = dt.datetime.strptime(row, '%b-%d %Y')\n",
    "    elif ',' in row: \n",
    "        date_time = dt.datetime.strptime(row, '%b %d, %Y')\n",
    "    else:\n",
    "        pass\n",
    "    dates.append(date_time.date())\n",
    "df['date'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        post_id  Unnamed: 1         username     date_time  \\\n",
       "2756  101571212     6847100    Darren Pachai  Jun 13, 2020   \n",
       "2757  101571212     6847100   Zulkifli Mamat  Jun 13, 2020   \n",
       "2758  101571212     6847100           CH Lee  Jun 13, 2020   \n",
       "2759  101571212     6847100  Benny Nasirelli  Jun 13, 2020   \n",
       "2760  101571212     6847100              許隆貴  Jun 13, 2020   \n",
       "\n",
       "                                           comments_raw        date  \n",
       "2756                                Health over economy  2020-06-13  \n",
       "2757  Double whammy? Try overblow cases of covid19 a...  2020-06-13  \n",
       "2758                                               🐦 👄   2020-06-13  \n",
       "2759  You don't need an analyst to tell you this. My...  2020-06-13  \n",
       "2760  If ask the millionaires or billionaires dormit...  2020-06-13  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>post_id</th>\n      <th>Unnamed: 1</th>\n      <th>username</th>\n      <th>date_time</th>\n      <th>comments_raw</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2756</th>\n      <td>101571212</td>\n      <td>6847100</td>\n      <td>Darren Pachai</td>\n      <td>Jun 13, 2020</td>\n      <td>Health over economy</td>\n      <td>2020-06-13</td>\n    </tr>\n    <tr>\n      <th>2757</th>\n      <td>101571212</td>\n      <td>6847100</td>\n      <td>Zulkifli Mamat</td>\n      <td>Jun 13, 2020</td>\n      <td>Double whammy? Try overblow cases of covid19 a...</td>\n      <td>2020-06-13</td>\n    </tr>\n    <tr>\n      <th>2758</th>\n      <td>101571212</td>\n      <td>6847100</td>\n      <td>CH Lee</td>\n      <td>Jun 13, 2020</td>\n      <td>🐦 👄</td>\n      <td>2020-06-13</td>\n    </tr>\n    <tr>\n      <th>2759</th>\n      <td>101571212</td>\n      <td>6847100</td>\n      <td>Benny Nasirelli</td>\n      <td>Jun 13, 2020</td>\n      <td>You don't need an analyst to tell you this. My...</td>\n      <td>2020-06-13</td>\n    </tr>\n    <tr>\n      <th>2760</th>\n      <td>101571212</td>\n      <td>6847100</td>\n      <td>許隆貴</td>\n      <td>Jun 13, 2020</td>\n      <td>If ask the millionaires or billionaires dormit...</td>\n      <td>2020-06-13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    if type(df.iloc[i]['date']) == 'str':\n",
    "        df.at[i, 'date'] = np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/chenjianyu/Desktop/testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}